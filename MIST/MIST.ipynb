{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuPLZJbKgya_",
        "outputId": "9d69195a-242b-43f0-9f5a-8a6ef75f3eb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ps708ud4gzS_",
        "outputId": "87386c65-d302-4a1a-f215-b1fa15cb3477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Thesis/Mist.zip\n",
            "  inflating: arima.py                \n",
            "  inflating: basic_ML.py             \n",
            "  inflating: CRIME-CHICAGO/.DS_Store  \n",
            "  inflating: CRIME-CHICAGO/8/test.npz  \n",
            "  inflating: CRIME-CHICAGO/8/train.npz  \n",
            "  inflating: CRIME-CHICAGO/8/val.npz  \n",
            "  inflating: CRIME-CHICAGO/chicago_crime_8.yaml  \n",
            "  inflating: CRIME-CHICAGO/chicago_crime_default.yaml  \n",
            "  inflating: CRIME-CHICAGO/default/test.npz  \n",
            "  inflating: CRIME-CHICAGO/default/train.npz  \n",
            "  inflating: CRIME-CHICAGO/default/val.npz  \n",
            "  inflating: CRIME-LA/.DS_Store      \n",
            "  inflating: CRIME-LA/36_2019/test.npz  \n",
            "  inflating: CRIME-LA/36_2019/train.npz  \n",
            "  inflating: CRIME-LA/36_2019/val.npz  \n",
            "  inflating: CRIME-LA/8/test.npz     \n",
            "  inflating: CRIME-LA/8/train.npz    \n",
            "  inflating: CRIME-LA/8/val.npz      \n",
            "  inflating: CRIME-LA/la_crime_36_2019.yaml  \n",
            "  inflating: CRIME-LA/la_crime_8.yaml  \n",
            "  inflating: embedding_file/emb_file_chi.txt  \n",
            "  inflating: embedding_file/emb_file_la.txt  \n",
            "  inflating: Mist.py                 \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/Thesis/Mist.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLqRzmyfvJy6",
        "outputId": "8b71052d-1b28-4462-f45c-62d39d9da130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Thesis/MiST_Holiday_Dataset.zip\n",
            "  inflating: Dataset/train.npz       \n",
            "  inflating: Dataset/val.npz         \n",
            "  inflating: Dataset/x_test_easter.npz  \n",
            "  inflating: Dataset/x_test_upto_MARCH.npz  \n",
            "  inflating: Dataset/x_test_xmas.npz  \n"
          ]
        }
      ],
      "source": [
        "# !unzip /content/drive/MyDrive/Thesis/data_2019_for_mist_4h.zip\n",
        "# !unzip /content/drive/MyDrive/Thesis/data_2019_for_mist.zip\n",
        "\n",
        "!unzip /content/drive/MyDrive/Thesis/MiST_Holiday_Dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm3xyW6d94I0",
        "outputId": "1cdaba5d-001c-4f6c-f355-8df2a92fd7e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-29 15:04:13.643286: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-29 15:04:15.398550: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-29 15:04:19.276028: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-29 15:04:19.277681: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-29 15:04:19.279167: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "Epoch 1/150\n",
            "2023-05-29 15:04:20.116041: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-29 15:04:20.117862: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-29 15:04:20.119564: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-05-29 15:04:21.442465: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-29 15:04:21.444245: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-29 15:04:21.447189: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.69282023-05-29 15:04:28.753726: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-29 15:04:28.755901: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-29 15:04:28.757903: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "10/10 [==============================] - 10s 679ms/step - loss: 0.6928 - val_loss: 0.6923\n",
            "Epoch 2/150\n",
            "10/10 [==============================] - 4s 351ms/step - loss: 0.6921 - val_loss: 0.6915\n",
            "Epoch 3/150\n",
            "10/10 [==============================] - 4s 435ms/step - loss: 0.6914 - val_loss: 0.6907\n",
            "Epoch 4/150\n",
            "10/10 [==============================] - 5s 518ms/step - loss: 0.6907 - val_loss: 0.6900\n",
            "Epoch 5/150\n",
            "10/10 [==============================] - 4s 352ms/step - loss: 0.6901 - val_loss: 0.6892\n",
            "Epoch 6/150\n",
            "10/10 [==============================] - 4s 355ms/step - loss: 0.6895 - val_loss: 0.6885\n",
            "Epoch 7/150\n",
            "10/10 [==============================] - 4s 366ms/step - loss: 0.6888 - val_loss: 0.6878\n",
            "Epoch 8/150\n",
            "10/10 [==============================] - 5s 498ms/step - loss: 0.6882 - val_loss: 0.6870\n",
            "Epoch 9/150\n",
            "10/10 [==============================] - 3s 330ms/step - loss: 0.6875 - val_loss: 0.6862\n",
            "Epoch 10/150\n",
            "10/10 [==============================] - 3s 325ms/step - loss: 0.6868 - val_loss: 0.6854\n",
            "Epoch 11/150\n",
            "10/10 [==============================] - 5s 487ms/step - loss: 0.6860 - val_loss: 0.6846\n",
            "Epoch 12/150\n",
            "10/10 [==============================] - 4s 407ms/step - loss: 0.6853 - val_loss: 0.6839\n",
            "Epoch 13/150\n",
            "10/10 [==============================] - 4s 401ms/step - loss: 0.6847 - val_loss: 0.6832\n",
            "Epoch 14/150\n",
            "10/10 [==============================] - 4s 413ms/step - loss: 0.6841 - val_loss: 0.6825\n",
            "Epoch 15/150\n",
            "10/10 [==============================] - 5s 467ms/step - loss: 0.6835 - val_loss: 0.6819\n",
            "Epoch 16/150\n",
            "10/10 [==============================] - 3s 344ms/step - loss: 0.6829 - val_loss: 0.6813\n",
            "Epoch 17/150\n",
            "10/10 [==============================] - 4s 364ms/step - loss: 0.6823 - val_loss: 0.6806\n",
            "Epoch 18/150\n",
            "10/10 [==============================] - 5s 548ms/step - loss: 0.6817 - val_loss: 0.6799\n",
            "Epoch 19/150\n",
            "10/10 [==============================] - 4s 362ms/step - loss: 0.6812 - val_loss: 0.6794\n",
            "Epoch 20/150\n",
            "10/10 [==============================] - 4s 365ms/step - loss: 0.6807 - val_loss: 0.6788\n",
            "Epoch 21/150\n",
            "10/10 [==============================] - 4s 373ms/step - loss: 0.6802 - val_loss: 0.6783\n",
            "Epoch 22/150\n",
            "10/10 [==============================] - 5s 460ms/step - loss: 0.6798 - val_loss: 0.6779\n",
            "Epoch 23/150\n",
            "10/10 [==============================] - 3s 352ms/step - loss: 0.6794 - val_loss: 0.6774\n",
            "Epoch 24/150\n",
            "10/10 [==============================] - 4s 356ms/step - loss: 0.6790 - val_loss: 0.6770\n",
            "Epoch 25/150\n",
            "10/10 [==============================] - 5s 513ms/step - loss: 0.6786 - val_loss: 0.6766\n",
            "Epoch 26/150\n",
            "10/10 [==============================] - 4s 381ms/step - loss: 0.6783 - val_loss: 0.6763\n",
            "Epoch 27/150\n",
            "10/10 [==============================] - 3s 342ms/step - loss: 0.6780 - val_loss: 0.6759\n",
            "Epoch 28/150\n",
            "10/10 [==============================] - 3s 352ms/step - loss: 0.6777 - val_loss: 0.6756\n",
            "Epoch 29/150\n",
            "10/10 [==============================] - 5s 540ms/step - loss: 0.6774 - val_loss: 0.6753\n",
            "Epoch 30/150\n",
            "10/10 [==============================] - 4s 355ms/step - loss: 0.6771 - val_loss: 0.6750\n",
            "Epoch 31/150\n",
            "10/10 [==============================] - 4s 354ms/step - loss: 0.6769 - val_loss: 0.6747\n",
            "Epoch 32/150\n",
            "10/10 [==============================] - 5s 531ms/step - loss: 0.6767 - val_loss: 0.6744\n",
            "Epoch 33/150\n",
            "10/10 [==============================] - 4s 384ms/step - loss: 0.6764 - val_loss: 0.6742\n",
            "Epoch 34/150\n",
            "10/10 [==============================] - 4s 436ms/step - loss: 0.6762 - val_loss: 0.6739\n",
            "Epoch 35/150\n",
            "10/10 [==============================] - 5s 497ms/step - loss: 0.6760 - val_loss: 0.6737\n",
            "Epoch 36/150\n",
            "10/10 [==============================] - 4s 418ms/step - loss: 0.6758 - val_loss: 0.6735\n",
            "Epoch 37/150\n",
            "10/10 [==============================] - 4s 393ms/step - loss: 0.6756 - val_loss: 0.6733\n",
            "Epoch 38/150\n",
            "10/10 [==============================] - 3s 335ms/step - loss: 0.6754 - val_loss: 0.6731\n",
            "Epoch 39/150\n",
            "10/10 [==============================] - 5s 511ms/step - loss: 0.6752 - val_loss: 0.6729\n",
            "Epoch 40/150\n",
            "10/10 [==============================] - 3s 337ms/step - loss: 0.6750 - val_loss: 0.6727\n",
            "Epoch 41/150\n",
            "10/10 [==============================] - 4s 377ms/step - loss: 0.6749 - val_loss: 0.6725\n",
            "Epoch 42/150\n",
            "10/10 [==============================] - 5s 523ms/step - loss: 0.6747 - val_loss: 0.6723\n",
            "Epoch 43/150\n",
            "10/10 [==============================] - 4s 373ms/step - loss: 0.6745 - val_loss: 0.6721\n",
            "Epoch 44/150\n",
            "10/10 [==============================] - 4s 355ms/step - loss: 0.6744 - val_loss: 0.6719\n",
            "Epoch 45/150\n",
            "10/10 [==============================] - 4s 389ms/step - loss: 0.6742 - val_loss: 0.6717\n",
            "Epoch 46/150\n",
            "10/10 [==============================] - 5s 458ms/step - loss: 0.6740 - val_loss: 0.6716\n",
            "Epoch 47/150\n",
            "10/10 [==============================] - 3s 334ms/step - loss: 0.6739 - val_loss: 0.6714\n",
            "Epoch 48/150\n",
            "10/10 [==============================] - 4s 356ms/step - loss: 0.6737 - val_loss: 0.6713\n",
            "Epoch 49/150\n",
            "10/10 [==============================] - 5s 472ms/step - loss: 0.6736 - val_loss: 0.6711\n",
            "Epoch 50/150\n",
            "10/10 [==============================] - 4s 376ms/step - loss: 0.6734 - val_loss: 0.6710\n",
            "Epoch 51/150\n",
            "10/10 [==============================] - 4s 388ms/step - loss: 0.6733 - val_loss: 0.6708\n",
            "Epoch 52/150\n",
            "10/10 [==============================] - 4s 416ms/step - loss: 0.6732 - val_loss: 0.6707\n",
            "Epoch 53/150\n",
            "10/10 [==============================] - 5s 486ms/step - loss: 0.6730 - val_loss: 0.6705\n",
            "Epoch 54/150\n",
            "10/10 [==============================] - 3s 354ms/step - loss: 0.6729 - val_loss: 0.6704\n",
            "Epoch 55/150\n",
            "10/10 [==============================] - 3s 338ms/step - loss: 0.6727 - val_loss: 0.6702\n",
            "Epoch 56/150\n",
            "10/10 [==============================] - 5s 505ms/step - loss: 0.6726 - val_loss: 0.6701\n",
            "Epoch 57/150\n",
            "10/10 [==============================] - 5s 441ms/step - loss: 0.6725 - val_loss: 0.6700\n",
            "Epoch 58/150\n",
            "10/10 [==============================] - 4s 358ms/step - loss: 0.6723 - val_loss: 0.6698\n",
            "Epoch 59/150\n",
            "10/10 [==============================] - 4s 445ms/step - loss: 0.6722 - val_loss: 0.6697\n",
            "Epoch 60/150\n",
            "10/10 [==============================] - 5s 456ms/step - loss: 0.6721 - val_loss: 0.6696\n",
            "Epoch 61/150\n",
            "10/10 [==============================] - 3s 329ms/step - loss: 0.6719 - val_loss: 0.6694\n",
            "Epoch 62/150\n",
            "10/10 [==============================] - 3s 349ms/step - loss: 0.6718 - val_loss: 0.6693\n",
            "Epoch 63/150\n",
            "10/10 [==============================] - 5s 542ms/step - loss: 0.6717 - val_loss: 0.6692\n",
            "Epoch 64/150\n",
            "10/10 [==============================] - 4s 381ms/step - loss: 0.6715 - val_loss: 0.6690\n",
            "Epoch 65/150\n",
            "10/10 [==============================] - 4s 367ms/step - loss: 0.6714 - val_loss: 0.6689\n",
            "Epoch 66/150\n",
            "10/10 [==============================] - 4s 444ms/step - loss: 0.6713 - val_loss: 0.6688\n",
            "Epoch 67/150\n",
            "10/10 [==============================] - 5s 498ms/step - loss: 0.6712 - val_loss: 0.6687\n",
            "Epoch 68/150\n",
            "10/10 [==============================] - 4s 389ms/step - loss: 0.6710 - val_loss: 0.6686\n",
            "Epoch 69/150\n",
            "10/10 [==============================] - 3s 355ms/step - loss: 0.6709 - val_loss: 0.6684\n",
            "Epoch 70/150\n",
            "10/10 [==============================] - 5s 510ms/step - loss: 0.6708 - val_loss: 0.6683\n",
            "Epoch 71/150\n",
            "10/10 [==============================] - 4s 354ms/step - loss: 0.6706 - val_loss: 0.6682\n",
            "Epoch 72/150\n",
            "10/10 [==============================] - 4s 371ms/step - loss: 0.6705 - val_loss: 0.6681\n",
            "Epoch 73/150\n",
            "10/10 [==============================] - 5s 522ms/step - loss: 0.6704 - val_loss: 0.6680\n",
            "Epoch 74/150\n",
            "10/10 [==============================] - 4s 347ms/step - loss: 0.6703 - val_loss: 0.6678\n",
            "Epoch 75/150\n",
            "10/10 [==============================] - 4s 404ms/step - loss: 0.6701 - val_loss: 0.6677\n",
            "Epoch 76/150\n",
            "10/10 [==============================] - 4s 349ms/step - loss: 0.6700 - val_loss: 0.6676\n",
            "Epoch 77/150\n",
            "10/10 [==============================] - 5s 491ms/step - loss: 0.6699 - val_loss: 0.6675\n",
            "Epoch 78/150\n",
            "10/10 [==============================] - 4s 425ms/step - loss: 0.6698 - val_loss: 0.6674\n",
            "Epoch 79/150\n",
            "10/10 [==============================] - 4s 388ms/step - loss: 0.6697 - val_loss: 0.6673\n",
            "Epoch 80/150\n",
            "10/10 [==============================] - 5s 566ms/step - loss: 0.6695 - val_loss: 0.6672\n",
            "Epoch 81/150\n",
            "10/10 [==============================] - 4s 391ms/step - loss: 0.6694 - val_loss: 0.6671\n",
            "Epoch 82/150\n",
            "10/10 [==============================] - 3s 340ms/step - loss: 0.6693 - val_loss: 0.6669\n",
            "Epoch 83/150\n",
            "10/10 [==============================] - 5s 513ms/step - loss: 0.6692 - val_loss: 0.6668\n",
            "Epoch 84/150\n",
            "10/10 [==============================] - 4s 404ms/step - loss: 0.6690 - val_loss: 0.6667\n",
            "Epoch 85/150\n",
            "10/10 [==============================] - 4s 385ms/step - loss: 0.6689 - val_loss: 0.6666\n",
            "Epoch 86/150\n",
            "10/10 [==============================] - 4s 404ms/step - loss: 0.6688 - val_loss: 0.6665\n",
            "Epoch 87/150\n",
            "10/10 [==============================] - 5s 467ms/step - loss: 0.6687 - val_loss: 0.6664\n",
            "Epoch 88/150\n",
            "10/10 [==============================] - 4s 419ms/step - loss: 0.6686 - val_loss: 0.6663\n",
            "Epoch 89/150\n",
            "10/10 [==============================] - 4s 371ms/step - loss: 0.6685 - val_loss: 0.6662\n",
            "Epoch 90/150\n",
            "10/10 [==============================] - 6s 572ms/step - loss: 0.6683 - val_loss: 0.6661\n",
            "Epoch 91/150\n",
            "10/10 [==============================] - 4s 386ms/step - loss: 0.6682 - val_loss: 0.6660\n",
            "Epoch 92/150\n",
            "10/10 [==============================] - 3s 337ms/step - loss: 0.6681 - val_loss: 0.6658\n",
            "Epoch 93/150\n",
            "10/10 [==============================] - 4s 456ms/step - loss: 0.6680 - val_loss: 0.6657\n",
            "Epoch 94/150\n",
            "10/10 [==============================] - 5s 456ms/step - loss: 0.6679 - val_loss: 0.6656\n",
            "Epoch 95/150\n",
            "10/10 [==============================] - 3s 342ms/step - loss: 0.6677 - val_loss: 0.6655\n",
            "Epoch 96/150\n",
            "10/10 [==============================] - 4s 362ms/step - loss: 0.6676 - val_loss: 0.6654\n",
            "Epoch 97/150\n",
            "10/10 [==============================] - 5s 520ms/step - loss: 0.6675 - val_loss: 0.6653\n",
            "Epoch 98/150\n",
            "10/10 [==============================] - 4s 367ms/step - loss: 0.6674 - val_loss: 0.6652\n",
            "Epoch 99/150\n",
            "10/10 [==============================] - 4s 386ms/step - loss: 0.6673 - val_loss: 0.6651\n",
            "Epoch 100/150\n",
            "10/10 [==============================] - 5s 531ms/step - loss: 0.6672 - val_loss: 0.6650\n",
            "Epoch 101/150\n",
            "10/10 [==============================] - 4s 378ms/step - loss: 0.6671 - val_loss: 0.6649\n",
            "Epoch 102/150\n",
            "10/10 [==============================] - 4s 354ms/step - loss: 0.6669 - val_loss: 0.6648\n",
            "Epoch 103/150\n",
            "10/10 [==============================] - 4s 433ms/step - loss: 0.6668 - val_loss: 0.6647\n",
            "Epoch 104/150\n",
            "10/10 [==============================] - 5s 490ms/step - loss: 0.6667 - val_loss: 0.6646\n",
            "Epoch 105/150\n",
            "10/10 [==============================] - 4s 411ms/step - loss: 0.6666 - val_loss: 0.6645\n",
            "Epoch 106/150\n",
            "10/10 [==============================] - 4s 420ms/step - loss: 0.6665 - val_loss: 0.6644\n",
            "Epoch 107/150\n",
            "10/10 [==============================] - 5s 506ms/step - loss: 0.6664 - val_loss: 0.6643\n",
            "Epoch 108/150\n",
            "10/10 [==============================] - 3s 335ms/step - loss: 0.6663 - val_loss: 0.6641\n",
            "Epoch 109/150\n",
            "10/10 [==============================] - 4s 403ms/step - loss: 0.6661 - val_loss: 0.6641\n",
            "Epoch 110/150\n",
            "10/10 [==============================] - 6s 583ms/step - loss: 0.6660 - val_loss: 0.6640\n",
            "Epoch 111/150\n",
            "10/10 [==============================] - 4s 361ms/step - loss: 0.6659 - val_loss: 0.6638\n",
            "Epoch 112/150\n",
            "10/10 [==============================] - 4s 389ms/step - loss: 0.6658 - val_loss: 0.6637\n",
            "Epoch 113/150\n",
            "10/10 [==============================] - 5s 509ms/step - loss: 0.6657 - val_loss: 0.6636\n",
            "Epoch 114/150\n",
            "10/10 [==============================] - 4s 432ms/step - loss: 0.6656 - val_loss: 0.6635\n",
            "Epoch 115/150\n",
            "10/10 [==============================] - 4s 376ms/step - loss: 0.6655 - val_loss: 0.6634\n",
            "Epoch 116/150\n",
            "10/10 [==============================] - 4s 439ms/step - loss: 0.6654 - val_loss: 0.6633\n",
            "Epoch 117/150\n",
            "10/10 [==============================] - 5s 491ms/step - loss: 0.6652 - val_loss: 0.6632\n",
            "Epoch 118/150\n",
            "10/10 [==============================] - 4s 387ms/step - loss: 0.6651 - val_loss: 0.6631\n",
            "Epoch 119/150\n",
            "10/10 [==============================] - 4s 398ms/step - loss: 0.6650 - val_loss: 0.6630\n",
            "Epoch 120/150\n",
            "10/10 [==============================] - 5s 533ms/step - loss: 0.6649 - val_loss: 0.6629\n",
            "Epoch 121/150\n",
            "10/10 [==============================] - 4s 376ms/step - loss: 0.6648 - val_loss: 0.6628\n",
            "Epoch 122/150\n",
            "10/10 [==============================] - 3s 351ms/step - loss: 0.6647 - val_loss: 0.6627\n",
            "Epoch 123/150\n",
            "10/10 [==============================] - 5s 525ms/step - loss: 0.6646 - val_loss: 0.6626\n",
            "Epoch 124/150\n",
            "10/10 [==============================] - 4s 406ms/step - loss: 0.6645 - val_loss: 0.6625\n",
            "Epoch 125/150\n",
            "10/10 [==============================] - 4s 386ms/step - loss: 0.6644 - val_loss: 0.6624\n",
            "Epoch 126/150\n",
            "10/10 [==============================] - 4s 429ms/step - loss: 0.6642 - val_loss: 0.6623\n",
            "Epoch 127/150\n",
            "10/10 [==============================] - 5s 456ms/step - loss: 0.6641 - val_loss: 0.6622\n",
            "Epoch 128/150\n",
            "10/10 [==============================] - 4s 403ms/step - loss: 0.6640 - val_loss: 0.6621\n",
            "Epoch 129/150\n",
            "10/10 [==============================] - 4s 386ms/step - loss: 0.6639 - val_loss: 0.6620\n",
            "Epoch 130/150\n",
            "10/10 [==============================] - 5s 528ms/step - loss: 0.6638 - val_loss: 0.6619\n",
            "Epoch 131/150\n",
            "10/10 [==============================] - 4s 368ms/step - loss: 0.6637 - val_loss: 0.6618\n",
            "Epoch 132/150\n",
            "10/10 [==============================] - 4s 392ms/step - loss: 0.6636 - val_loss: 0.6617\n",
            "Epoch 133/150\n",
            "10/10 [==============================] - 4s 460ms/step - loss: 0.6635 - val_loss: 0.6616\n",
            "Epoch 134/150\n",
            "10/10 [==============================] - 4s 428ms/step - loss: 0.6634 - val_loss: 0.6615\n",
            "Epoch 135/150\n",
            "10/10 [==============================] - 3s 340ms/step - loss: 0.6633 - val_loss: 0.6614\n",
            "Epoch 136/150\n",
            "10/10 [==============================] - 4s 353ms/step - loss: 0.6632 - val_loss: 0.6613\n",
            "Epoch 137/150\n",
            "10/10 [==============================] - 5s 552ms/step - loss: 0.6631 - val_loss: 0.6612\n",
            "Epoch 138/150\n",
            "10/10 [==============================] - 4s 384ms/step - loss: 0.6630 - val_loss: 0.6611\n",
            "Epoch 139/150\n",
            "10/10 [==============================] - 3s 337ms/step - loss: 0.6629 - val_loss: 0.6610\n",
            "Epoch 140/150\n",
            "10/10 [==============================] - 5s 531ms/step - loss: 0.6628 - val_loss: 0.6609\n",
            "Epoch 141/150\n",
            "10/10 [==============================] - 4s 359ms/step - loss: 0.6627 - val_loss: 0.6608\n",
            "Epoch 142/150\n",
            "10/10 [==============================] - 4s 373ms/step - loss: 0.6625 - val_loss: 0.6607\n",
            "Epoch 143/150\n",
            "10/10 [==============================] - 4s 428ms/step - loss: 0.6624 - val_loss: 0.6606\n",
            "Epoch 144/150\n",
            "10/10 [==============================] - 5s 529ms/step - loss: 0.6623 - val_loss: 0.6605\n",
            "Epoch 145/150\n",
            "10/10 [==============================] - 4s 369ms/step - loss: 0.6622 - val_loss: 0.6604\n",
            "Epoch 146/150\n",
            "10/10 [==============================] - 4s 431ms/step - loss: 0.6621 - val_loss: 0.6603\n",
            "Epoch 147/150\n",
            "10/10 [==============================] - 5s 513ms/step - loss: 0.6620 - val_loss: 0.6602\n",
            "Epoch 148/150\n",
            "10/10 [==============================] - 4s 417ms/step - loss: 0.6619 - val_loss: 0.6601\n",
            "Epoch 149/150\n",
            "10/10 [==============================] - 4s 362ms/step - loss: 0.6618 - val_loss: 0.6600\n",
            "Epoch 150/150\n",
            "10/10 [==============================] - 6s 592ms/step - loss: 0.6617 - val_loss: 0.6599\n",
            "2023-05-29 15:15:45.327575: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-29 15:15:45.329275: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-29 15:15:45.330784: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "3/3 [==============================] - 1s 117ms/step\n",
            "(82, 616) (82, 616)\n",
            "The ratio of abnormal events in the test set is: 0.38990734874881217\n",
            "auc for MIST:  0.5668186007559898\n",
            "macro-f1: 0.5223614788793087\n",
            "micro-f1: 0.5482105744847179\n"
          ]
        }
      ],
      "source": [
        "!python /content/Mist.py "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdXpRE1ehAN3",
        "outputId": "e232649c-a1e1-4e1b-edd2-7f2791a81714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "66  started\n",
            "2023-05-12 20:16:37.649370: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-12 20:16:40.180327: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-12 20:16:46.053349: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 20:16:46.055573: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 20:16:46.057224: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "Epoch 1/100\n",
            "2023-05-12 20:16:47.285828: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 20:16:47.287963: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 20:16:47.289540: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-05-12 20:16:48.608365: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 20:16:48.610060: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 20:16:48.611746: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "48/48 [==============================] - ETA: 0s - loss: 0.68142023-05-12 20:17:08.300973: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 20:17:08.302553: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 20:17:08.303987: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "48/48 [==============================] - 24s 429ms/step - loss: 0.6814 - val_loss: 0.6687\n",
            "Epoch 2/100\n",
            "48/48 [==============================] - 19s 393ms/step - loss: 0.6539 - val_loss: 0.6392\n",
            "Epoch 3/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.6275 - val_loss: 0.6155\n",
            "Epoch 4/100\n",
            "48/48 [==============================] - 20s 421ms/step - loss: 0.6046 - val_loss: 0.5933\n",
            "Epoch 5/100\n",
            "48/48 [==============================] - 20s 416ms/step - loss: 0.5829 - val_loss: 0.5721\n",
            "Epoch 6/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.5621 - val_loss: 0.5518\n",
            "Epoch 7/100\n",
            "48/48 [==============================] - 21s 440ms/step - loss: 0.5422 - val_loss: 0.5323\n",
            "Epoch 8/100\n",
            "48/48 [==============================] - 19s 388ms/step - loss: 0.5231 - val_loss: 0.5136\n",
            "Epoch 9/100\n",
            "48/48 [==============================] - 18s 386ms/step - loss: 0.5048 - val_loss: 0.4957\n",
            "Epoch 10/100\n",
            "48/48 [==============================] - 24s 508ms/step - loss: 0.4872 - val_loss: 0.4785\n",
            "Epoch 11/100\n",
            "48/48 [==============================] - 19s 402ms/step - loss: 0.4704 - val_loss: 0.4620\n",
            "Epoch 12/100\n",
            "48/48 [==============================] - 19s 395ms/step - loss: 0.4542 - val_loss: 0.4462\n",
            "Epoch 13/100\n",
            "48/48 [==============================] - 20s 423ms/step - loss: 0.4387 - val_loss: 0.4311\n",
            "Epoch 14/100\n",
            "48/48 [==============================] - 19s 397ms/step - loss: 0.4239 - val_loss: 0.4165\n",
            "Epoch 15/100\n",
            "48/48 [==============================] - 20s 428ms/step - loss: 0.4096 - val_loss: 0.4026\n",
            "Epoch 16/100\n",
            "48/48 [==============================] - 20s 406ms/step - loss: 0.3959 - val_loss: 0.3892\n",
            "Epoch 17/100\n",
            "48/48 [==============================] - 19s 393ms/step - loss: 0.3828 - val_loss: 0.3763\n",
            "Epoch 18/100\n",
            "48/48 [==============================] - 20s 425ms/step - loss: 0.3702 - val_loss: 0.3640\n",
            "Epoch 19/100\n",
            "48/48 [==============================] - 19s 388ms/step - loss: 0.3581 - val_loss: 0.3521\n",
            "Epoch 20/100\n",
            "48/48 [==============================] - 19s 388ms/step - loss: 0.3465 - val_loss: 0.3408\n",
            "Epoch 21/100\n",
            "48/48 [==============================] - 20s 424ms/step - loss: 0.3353 - val_loss: 0.3299\n",
            "Epoch 22/100\n",
            "48/48 [==============================] - 19s 393ms/step - loss: 0.3246 - val_loss: 0.3194\n",
            "Epoch 23/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.3143 - val_loss: 0.3093\n",
            "Epoch 24/100\n",
            "48/48 [==============================] - 20s 424ms/step - loss: 0.3044 - val_loss: 0.2996\n",
            "Epoch 25/100\n",
            "48/48 [==============================] - 19s 392ms/step - loss: 0.2950 - val_loss: 0.2903\n",
            "Epoch 26/100\n",
            "48/48 [==============================] - 19s 394ms/step - loss: 0.2858 - val_loss: 0.2814\n",
            "Epoch 27/100\n",
            "48/48 [==============================] - 20s 422ms/step - loss: 0.2771 - val_loss: 0.2728\n",
            "Epoch 28/100\n",
            "48/48 [==============================] - 19s 395ms/step - loss: 0.2686 - val_loss: 0.2646\n",
            "Epoch 29/100\n",
            "48/48 [==============================] - 19s 392ms/step - loss: 0.2605 - val_loss: 0.2566\n",
            "Epoch 30/100\n",
            "48/48 [==============================] - 21s 440ms/step - loss: 0.2527 - val_loss: 0.2490\n",
            "Epoch 31/100\n",
            "48/48 [==============================] - 19s 390ms/step - loss: 0.2452 - val_loss: 0.2416\n",
            "Epoch 32/100\n",
            "48/48 [==============================] - 19s 392ms/step - loss: 0.2380 - val_loss: 0.2346\n",
            "Epoch 33/100\n",
            "48/48 [==============================] - 20s 429ms/step - loss: 0.2311 - val_loss: 0.2277\n",
            "Epoch 34/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.2244 - val_loss: 0.2212\n",
            "Epoch 35/100\n",
            "48/48 [==============================] - 19s 393ms/step - loss: 0.2179 - val_loss: 0.2149\n",
            "Epoch 36/100\n",
            "48/48 [==============================] - 20s 425ms/step - loss: 0.2117 - val_loss: 0.2088\n",
            "Epoch 37/100\n",
            "48/48 [==============================] - 19s 394ms/step - loss: 0.2058 - val_loss: 0.2029\n",
            "Epoch 38/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.2000 - val_loss: 0.1973\n",
            "Epoch 39/100\n",
            "48/48 [==============================] - 20s 427ms/step - loss: 0.1944 - val_loss: 0.1918\n",
            "Epoch 40/100\n",
            "48/48 [==============================] - 19s 393ms/step - loss: 0.1891 - val_loss: 0.1866\n",
            "Epoch 41/100\n",
            "48/48 [==============================] - 19s 393ms/step - loss: 0.1839 - val_loss: 0.1815\n",
            "Epoch 42/100\n",
            "48/48 [==============================] - 23s 477ms/step - loss: 0.1789 - val_loss: 0.1766\n",
            "Epoch 43/100\n",
            "48/48 [==============================] - 19s 392ms/step - loss: 0.1741 - val_loss: 0.1719\n",
            "Epoch 44/100\n",
            "48/48 [==============================] - 19s 393ms/step - loss: 0.1695 - val_loss: 0.1673\n",
            "Epoch 45/100\n",
            "48/48 [==============================] - 21s 431ms/step - loss: 0.1650 - val_loss: 0.1629\n",
            "Epoch 46/100\n",
            "48/48 [==============================] - 19s 390ms/step - loss: 0.1607 - val_loss: 0.1587\n",
            "Epoch 47/100\n",
            "48/48 [==============================] - 19s 390ms/step - loss: 0.1565 - val_loss: 0.1546\n",
            "Epoch 48/100\n",
            "48/48 [==============================] - 21s 430ms/step - loss: 0.1524 - val_loss: 0.1506\n",
            "Epoch 49/100\n",
            "48/48 [==============================] - 19s 392ms/step - loss: 0.1485 - val_loss: 0.1468\n",
            "Epoch 50/100\n",
            "48/48 [==============================] - 19s 393ms/step - loss: 0.1448 - val_loss: 0.1431\n",
            "Epoch 51/100\n",
            "48/48 [==============================] - 20s 426ms/step - loss: 0.1411 - val_loss: 0.1395\n",
            "Epoch 52/100\n",
            "48/48 [==============================] - 19s 388ms/step - loss: 0.1376 - val_loss: 0.1360\n",
            "Epoch 53/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.1342 - val_loss: 0.1327\n",
            "Epoch 54/100\n",
            "48/48 [==============================] - 21s 432ms/step - loss: 0.1309 - val_loss: 0.1294\n",
            "Epoch 55/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.1277 - val_loss: 0.1263\n",
            "Epoch 56/100\n",
            "48/48 [==============================] - 19s 393ms/step - loss: 0.1246 - val_loss: 0.1232\n",
            "Epoch 57/100\n",
            "48/48 [==============================] - 21s 434ms/step - loss: 0.1216 - val_loss: 0.1203\n",
            "Epoch 58/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.1187 - val_loss: 0.1174\n",
            "Epoch 59/100\n",
            "48/48 [==============================] - 19s 395ms/step - loss: 0.1159 - val_loss: 0.1147\n",
            "Epoch 60/100\n",
            "48/48 [==============================] - 21s 431ms/step - loss: 0.1131 - val_loss: 0.1120\n",
            "Epoch 61/100\n",
            "48/48 [==============================] - 19s 393ms/step - loss: 0.1105 - val_loss: 0.1094\n",
            "Epoch 62/100\n",
            "48/48 [==============================] - 19s 392ms/step - loss: 0.1079 - val_loss: 0.1069\n",
            "Epoch 63/100\n",
            "48/48 [==============================] - 21s 430ms/step - loss: 0.1055 - val_loss: 0.1045\n",
            "Epoch 64/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.1031 - val_loss: 0.1021\n",
            "Epoch 65/100\n",
            "48/48 [==============================] - 19s 399ms/step - loss: 0.1007 - val_loss: 0.0998\n",
            "Epoch 66/100\n",
            "48/48 [==============================] - 20s 421ms/step - loss: 0.0985 - val_loss: 0.0976\n",
            "Epoch 67/100\n",
            "48/48 [==============================] - 19s 388ms/step - loss: 0.0963 - val_loss: 0.0954\n",
            "Epoch 68/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.0941 - val_loss: 0.0933\n",
            "Epoch 69/100\n",
            "48/48 [==============================] - 20s 424ms/step - loss: 0.0921 - val_loss: 0.0913\n",
            "Epoch 70/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.0901 - val_loss: 0.0893\n",
            "Epoch 71/100\n",
            "48/48 [==============================] - 20s 423ms/step - loss: 0.0881 - val_loss: 0.0874\n",
            "Epoch 72/100\n",
            "48/48 [==============================] - 20s 404ms/step - loss: 0.0862 - val_loss: 0.0855\n",
            "Epoch 73/100\n",
            "48/48 [==============================] - 22s 459ms/step - loss: 0.0844 - val_loss: 0.0837\n",
            "Epoch 74/100\n",
            "48/48 [==============================] - 21s 447ms/step - loss: 0.0826 - val_loss: 0.0820\n",
            "Epoch 75/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.0809 - val_loss: 0.0803\n",
            "Epoch 76/100\n",
            "48/48 [==============================] - 19s 392ms/step - loss: 0.0792 - val_loss: 0.0786\n",
            "Epoch 77/100\n",
            "48/48 [==============================] - 21s 429ms/step - loss: 0.0776 - val_loss: 0.0770\n",
            "Epoch 78/100\n",
            "48/48 [==============================] - 19s 392ms/step - loss: 0.0760 - val_loss: 0.0755\n",
            "Epoch 79/100\n",
            "48/48 [==============================] - 19s 396ms/step - loss: 0.0744 - val_loss: 0.0739\n",
            "Epoch 80/100\n",
            "48/48 [==============================] - 21s 433ms/step - loss: 0.0729 - val_loss: 0.0725\n",
            "Epoch 81/100\n",
            "48/48 [==============================] - 19s 388ms/step - loss: 0.0715 - val_loss: 0.0710\n",
            "Epoch 82/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.0700 - val_loss: 0.0696\n",
            "Epoch 83/100\n",
            "48/48 [==============================] - 21s 433ms/step - loss: 0.0687 - val_loss: 0.0683\n",
            "Epoch 84/100\n",
            "48/48 [==============================] - 19s 394ms/step - loss: 0.0673 - val_loss: 0.0669\n",
            "Epoch 85/100\n",
            "48/48 [==============================] - 19s 399ms/step - loss: 0.0660 - val_loss: 0.0657\n",
            "Epoch 86/100\n",
            "48/48 [==============================] - 20s 418ms/step - loss: 0.0647 - val_loss: 0.0644\n",
            "Epoch 87/100\n",
            "48/48 [==============================] - 19s 395ms/step - loss: 0.0635 - val_loss: 0.0632\n",
            "Epoch 88/100\n",
            "48/48 [==============================] - 20s 425ms/step - loss: 0.0623 - val_loss: 0.0620\n",
            "Epoch 89/100\n",
            "48/48 [==============================] - 19s 403ms/step - loss: 0.0611 - val_loss: 0.0609\n",
            "Epoch 90/100\n",
            "48/48 [==============================] - 19s 395ms/step - loss: 0.0600 - val_loss: 0.0597\n",
            "Epoch 91/100\n",
            "48/48 [==============================] - 20s 422ms/step - loss: 0.0589 - val_loss: 0.0586\n",
            "Epoch 92/100\n",
            "48/48 [==============================] - 19s 395ms/step - loss: 0.0578 - val_loss: 0.0576\n",
            "Epoch 93/100\n",
            "48/48 [==============================] - 19s 396ms/step - loss: 0.0568 - val_loss: 0.0566\n",
            "Epoch 94/100\n",
            "48/48 [==============================] - 21s 447ms/step - loss: 0.0557 - val_loss: 0.0555\n",
            "Epoch 95/100\n",
            "48/48 [==============================] - 19s 393ms/step - loss: 0.0547 - val_loss: 0.0546\n",
            "Epoch 96/100\n",
            "48/48 [==============================] - 19s 395ms/step - loss: 0.0538 - val_loss: 0.0536\n",
            "Epoch 97/100\n",
            "48/48 [==============================] - 21s 429ms/step - loss: 0.0528 - val_loss: 0.0527\n",
            "Epoch 98/100\n",
            "48/48 [==============================] - 19s 396ms/step - loss: 0.0519 - val_loss: 0.0518\n",
            "Epoch 99/100\n",
            "48/48 [==============================] - 19s 392ms/step - loss: 0.0510 - val_loss: 0.0509\n",
            "Epoch 100/100\n",
            "48/48 [==============================] - 21s 426ms/step - loss: 0.0501 - val_loss: 0.0500\n",
            "2023-05-12 20:50:12.453901: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 20:50:12.455549: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 20:50:12.457380: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "14/14 [==============================] - 3s 157ms/step\n",
            "(436, 616) (436, 616)\n",
            "The ratio of abnormal events in the test set is: 0.0025839985702371024\n",
            "auc for MIST:  0.9483989219133797\n",
            "macro-f1: 0.04566704592380086\n",
            "micro-f1: 0.04780602052765723\n",
            "66  finished\n",
            "67  started\n",
            "2023-05-12 20:50:19.406740: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-12 20:50:20.716815: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-12 20:50:25.774280: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 20:50:25.776423: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 20:50:25.778435: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "Epoch 1/100\n",
            "2023-05-12 20:50:27.011497: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 20:50:27.013935: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 20:50:27.015712: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-05-12 20:50:28.346958: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 20:50:28.348813: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 20:50:28.350597: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "48/48 [==============================] - ETA: 0s - loss: 0.68142023-05-12 20:50:48.222621: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 20:50:48.224209: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 20:50:48.225712: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "48/48 [==============================] - 23s 407ms/step - loss: 0.6814 - val_loss: 0.6688\n",
            "Epoch 2/100\n",
            "48/48 [==============================] - 20s 423ms/step - loss: 0.6544 - val_loss: 0.6398\n",
            "Epoch 3/100\n",
            "48/48 [==============================] - 19s 395ms/step - loss: 0.6280 - val_loss: 0.6159\n",
            "Epoch 4/100\n",
            "48/48 [==============================] - 18s 386ms/step - loss: 0.6050 - val_loss: 0.5937\n",
            "Epoch 5/100\n",
            "48/48 [==============================] - 21s 430ms/step - loss: 0.5833 - val_loss: 0.5725\n",
            "Epoch 6/100\n",
            "48/48 [==============================] - 18s 378ms/step - loss: 0.5625 - val_loss: 0.5521\n",
            "Epoch 7/100\n",
            "48/48 [==============================] - 19s 390ms/step - loss: 0.5426 - val_loss: 0.5327\n",
            "Epoch 8/100\n",
            "48/48 [==============================] - 21s 438ms/step - loss: 0.5235 - val_loss: 0.5140\n",
            "Epoch 9/100\n",
            "48/48 [==============================] - 19s 404ms/step - loss: 0.5052 - val_loss: 0.4961\n",
            "Epoch 10/100\n",
            "48/48 [==============================] - 19s 407ms/step - loss: 0.4876 - val_loss: 0.4789\n",
            "Epoch 11/100\n",
            "48/48 [==============================] - 21s 429ms/step - loss: 0.4708 - val_loss: 0.4624\n",
            "Epoch 12/100\n",
            "48/48 [==============================] - 19s 393ms/step - loss: 0.4546 - val_loss: 0.4466\n",
            "Epoch 13/100\n",
            "48/48 [==============================] - 20s 423ms/step - loss: 0.4391 - val_loss: 0.4315\n",
            "Epoch 14/100\n",
            "48/48 [==============================] - 19s 396ms/step - loss: 0.4243 - val_loss: 0.4169\n",
            "Epoch 15/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.4100 - val_loss: 0.4030\n",
            "Epoch 16/100\n",
            "48/48 [==============================] - 20s 409ms/step - loss: 0.3963 - val_loss: 0.3896\n",
            "Epoch 17/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.3832 - val_loss: 0.3767\n",
            "Epoch 18/100\n",
            "48/48 [==============================] - 18s 376ms/step - loss: 0.3706 - val_loss: 0.3644\n",
            "Epoch 19/100\n",
            "48/48 [==============================] - 18s 374ms/step - loss: 0.3585 - val_loss: 0.3526\n",
            "Epoch 20/100\n",
            "48/48 [==============================] - 21s 430ms/step - loss: 0.3469 - val_loss: 0.3412\n",
            "Epoch 21/100\n",
            "48/48 [==============================] - 18s 377ms/step - loss: 0.3358 - val_loss: 0.3303\n",
            "Epoch 22/100\n",
            "48/48 [==============================] - 18s 376ms/step - loss: 0.3251 - val_loss: 0.3198\n",
            "Epoch 23/100\n",
            "48/48 [==============================] - 20s 417ms/step - loss: 0.3148 - val_loss: 0.3097\n",
            "Epoch 24/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.3049 - val_loss: 0.3001\n",
            "Epoch 25/100\n",
            "48/48 [==============================] - 18s 378ms/step - loss: 0.2954 - val_loss: 0.2908\n",
            "Epoch 26/100\n",
            "48/48 [==============================] - 20s 412ms/step - loss: 0.2863 - val_loss: 0.2819\n",
            "Epoch 27/100\n",
            "48/48 [==============================] - 19s 385ms/step - loss: 0.2776 - val_loss: 0.2733\n",
            "Epoch 28/100\n",
            "48/48 [==============================] - 18s 377ms/step - loss: 0.2691 - val_loss: 0.2650\n",
            "Epoch 29/100\n",
            "48/48 [==============================] - 18s 378ms/step - loss: 0.2610 - val_loss: 0.2571\n",
            "Epoch 30/100\n",
            "48/48 [==============================] - 20s 414ms/step - loss: 0.2533 - val_loss: 0.2495\n",
            "Epoch 31/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.2458 - val_loss: 0.2421\n",
            "Epoch 32/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.2386 - val_loss: 0.2350\n",
            "Epoch 33/100\n",
            "48/48 [==============================] - 20s 426ms/step - loss: 0.2316 - val_loss: 0.2282\n",
            "Epoch 34/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.2249 - val_loss: 0.2217\n",
            "Epoch 35/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.2185 - val_loss: 0.2154\n",
            "Epoch 36/100\n",
            "48/48 [==============================] - 20s 411ms/step - loss: 0.2123 - val_loss: 0.2093\n",
            "Epoch 37/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.2063 - val_loss: 0.2035\n",
            "Epoch 38/100\n",
            "48/48 [==============================] - 18s 378ms/step - loss: 0.2006 - val_loss: 0.1978\n",
            "Epoch 39/100\n",
            "48/48 [==============================] - 18s 386ms/step - loss: 0.1950 - val_loss: 0.1924\n",
            "Epoch 40/100\n",
            "48/48 [==============================] - 20s 409ms/step - loss: 0.1897 - val_loss: 0.1871\n",
            "Epoch 41/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.1845 - val_loss: 0.1821\n",
            "Epoch 42/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.1795 - val_loss: 0.1772\n",
            "Epoch 43/100\n",
            "48/48 [==============================] - 20s 411ms/step - loss: 0.1747 - val_loss: 0.1725\n",
            "Epoch 44/100\n",
            "48/48 [==============================] - 19s 384ms/step - loss: 0.1701 - val_loss: 0.1679\n",
            "Epoch 45/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.1656 - val_loss: 0.1635\n",
            "Epoch 46/100\n",
            "48/48 [==============================] - 18s 387ms/step - loss: 0.1613 - val_loss: 0.1593\n",
            "Epoch 47/100\n",
            "48/48 [==============================] - 20s 404ms/step - loss: 0.1571 - val_loss: 0.1552\n",
            "Epoch 48/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.1531 - val_loss: 0.1512\n",
            "Epoch 49/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.1492 - val_loss: 0.1474\n",
            "Epoch 50/100\n",
            "48/48 [==============================] - 21s 430ms/step - loss: 0.1454 - val_loss: 0.1437\n",
            "Epoch 51/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.1418 - val_loss: 0.1401\n",
            "Epoch 52/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.1383 - val_loss: 0.1367\n",
            "Epoch 53/100\n",
            "48/48 [==============================] - 20s 422ms/step - loss: 0.1349 - val_loss: 0.1333\n",
            "Epoch 54/100\n",
            "48/48 [==============================] - 18s 376ms/step - loss: 0.1316 - val_loss: 0.1301\n",
            "Epoch 55/100\n",
            "48/48 [==============================] - 18s 378ms/step - loss: 0.1284 - val_loss: 0.1269\n",
            "Epoch 56/100\n",
            "48/48 [==============================] - 20s 413ms/step - loss: 0.1253 - val_loss: 0.1239\n",
            "Epoch 57/100\n",
            "48/48 [==============================] - 19s 386ms/step - loss: 0.1223 - val_loss: 0.1210\n",
            "Epoch 58/100\n",
            "48/48 [==============================] - 18s 378ms/step - loss: 0.1194 - val_loss: 0.1181\n",
            "Epoch 59/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.1166 - val_loss: 0.1154\n",
            "Epoch 60/100\n",
            "48/48 [==============================] - 20s 408ms/step - loss: 0.1139 - val_loss: 0.1127\n",
            "Epoch 61/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.1113 - val_loss: 0.1101\n",
            "Epoch 62/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.1087 - val_loss: 0.1076\n",
            "Epoch 63/100\n",
            "48/48 [==============================] - 20s 413ms/step - loss: 0.1062 - val_loss: 0.1052\n",
            "Epoch 64/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.1039 - val_loss: 0.1028\n",
            "Epoch 65/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.1015 - val_loss: 0.1005\n",
            "Epoch 66/100\n",
            "48/48 [==============================] - 20s 410ms/step - loss: 0.0993 - val_loss: 0.0983\n",
            "Epoch 67/100\n",
            "48/48 [==============================] - 19s 385ms/step - loss: 0.0971 - val_loss: 0.0962\n",
            "Epoch 68/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.0950 - val_loss: 0.0941\n",
            "Epoch 69/100\n",
            "48/48 [==============================] - 18s 377ms/step - loss: 0.0929 - val_loss: 0.0921\n",
            "Epoch 70/100\n",
            "48/48 [==============================] - 20s 411ms/step - loss: 0.0909 - val_loss: 0.0901\n",
            "Epoch 71/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.0890 - val_loss: 0.0882\n",
            "Epoch 72/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.0871 - val_loss: 0.0863\n",
            "Epoch 73/100\n",
            "48/48 [==============================] - 20s 420ms/step - loss: 0.0853 - val_loss: 0.0845\n",
            "Epoch 74/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.0835 - val_loss: 0.0828\n",
            "Epoch 75/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.0818 - val_loss: 0.0811\n",
            "Epoch 76/100\n",
            "48/48 [==============================] - 20s 410ms/step - loss: 0.0801 - val_loss: 0.0794\n",
            "Epoch 77/100\n",
            "48/48 [==============================] - 19s 386ms/step - loss: 0.0785 - val_loss: 0.0778\n",
            "Epoch 78/100\n",
            "48/48 [==============================] - 18s 378ms/step - loss: 0.0769 - val_loss: 0.0763\n",
            "Epoch 79/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.0753 - val_loss: 0.0748\n",
            "Epoch 80/100\n",
            "48/48 [==============================] - 20s 414ms/step - loss: 0.0738 - val_loss: 0.0733\n",
            "Epoch 81/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.0724 - val_loss: 0.0719\n",
            "Epoch 82/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.0710 - val_loss: 0.0705\n",
            "Epoch 83/100\n",
            "48/48 [==============================] - 20s 412ms/step - loss: 0.0696 - val_loss: 0.0691\n",
            "Epoch 84/100\n",
            "48/48 [==============================] - 18s 377ms/step - loss: 0.0683 - val_loss: 0.0678\n",
            "Epoch 85/100\n",
            "48/48 [==============================] - 18s 375ms/step - loss: 0.0670 - val_loss: 0.0665\n",
            "Epoch 86/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.0657 - val_loss: 0.0653\n",
            "Epoch 87/100\n",
            "48/48 [==============================] - 20s 408ms/step - loss: 0.0645 - val_loss: 0.0641\n",
            "Epoch 88/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.0633 - val_loss: 0.0629\n",
            "Epoch 89/100\n",
            "48/48 [==============================] - 18s 378ms/step - loss: 0.0621 - val_loss: 0.0617\n",
            "Epoch 90/100\n",
            "48/48 [==============================] - 20s 418ms/step - loss: 0.0610 - val_loss: 0.0606\n",
            "Epoch 91/100\n",
            "48/48 [==============================] - 18s 378ms/step - loss: 0.0599 - val_loss: 0.0595\n",
            "Epoch 92/100\n",
            "48/48 [==============================] - 18s 376ms/step - loss: 0.0588 - val_loss: 0.0585\n",
            "Epoch 93/100\n",
            "48/48 [==============================] - 19s 390ms/step - loss: 0.0578 - val_loss: 0.0575\n",
            "Epoch 94/100\n",
            "48/48 [==============================] - 19s 399ms/step - loss: 0.0567 - val_loss: 0.0565\n",
            "Epoch 95/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.0558 - val_loss: 0.0555\n",
            "Epoch 96/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.0548 - val_loss: 0.0545\n",
            "Epoch 97/100\n",
            "48/48 [==============================] - 20s 429ms/step - loss: 0.0539 - val_loss: 0.0536\n",
            "Epoch 98/100\n",
            "48/48 [==============================] - 18s 377ms/step - loss: 0.0529 - val_loss: 0.0527\n",
            "Epoch 99/100\n",
            "48/48 [==============================] - 18s 378ms/step - loss: 0.0521 - val_loss: 0.0518\n",
            "Epoch 100/100\n",
            "48/48 [==============================] - 20s 413ms/step - loss: 0.0512 - val_loss: 0.0510\n",
            "2023-05-12 21:22:52.144349: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 21:22:52.145992: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 21:22:52.147502: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "14/14 [==============================] - 3s 169ms/step\n",
            "(436, 616) (436, 616)\n",
            "The ratio of abnormal events in the test set is: 0.0028744191588228286\n",
            "auc for MIST:  0.9664381413272393\n",
            "macro-f1: 0.07602166479436875\n",
            "micro-f1: 0.0790983606557377\n",
            "67  finished\n",
            "68  started\n",
            "2023-05-12 21:22:57.573946: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-12 21:22:59.074405: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-12 21:23:02.514504: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 21:23:02.516057: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 21:23:02.517487: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "Epoch 1/100\n",
            "2023-05-12 21:23:03.595105: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 21:23:03.596784: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 21:23:03.598325: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-05-12 21:23:04.880475: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 21:23:04.882387: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 21:23:04.884271: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "48/48 [==============================] - ETA: 0s - loss: 0.68142023-05-12 21:23:25.252937: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 21:23:25.255040: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 21:23:25.257076: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "48/48 [==============================] - 25s 455ms/step - loss: 0.6814 - val_loss: 0.6685\n",
            "Epoch 2/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.6539 - val_loss: 0.6395\n",
            "Epoch 3/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.6277 - val_loss: 0.6158\n",
            "Epoch 4/100\n",
            "48/48 [==============================] - 20s 423ms/step - loss: 0.6048 - val_loss: 0.5936\n",
            "Epoch 5/100\n",
            "48/48 [==============================] - 19s 393ms/step - loss: 0.5831 - val_loss: 0.5723\n",
            "Epoch 6/100\n",
            "48/48 [==============================] - 19s 390ms/step - loss: 0.5623 - val_loss: 0.5520\n",
            "Epoch 7/100\n",
            "48/48 [==============================] - 20s 428ms/step - loss: 0.5424 - val_loss: 0.5325\n",
            "Epoch 8/100\n",
            "48/48 [==============================] - 19s 390ms/step - loss: 0.5233 - val_loss: 0.5139\n",
            "Epoch 9/100\n",
            "48/48 [==============================] - 19s 392ms/step - loss: 0.5050 - val_loss: 0.4960\n",
            "Epoch 10/100\n",
            "48/48 [==============================] - 20s 427ms/step - loss: 0.4875 - val_loss: 0.4788\n",
            "Epoch 11/100\n",
            "48/48 [==============================] - 19s 396ms/step - loss: 0.4706 - val_loss: 0.4623\n",
            "Epoch 12/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.4545 - val_loss: 0.4465\n",
            "Epoch 13/100\n",
            "48/48 [==============================] - 20s 426ms/step - loss: 0.4390 - val_loss: 0.4313\n",
            "Epoch 14/100\n",
            "48/48 [==============================] - 19s 395ms/step - loss: 0.4241 - val_loss: 0.4168\n",
            "Epoch 15/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.4098 - val_loss: 0.4028\n",
            "Epoch 16/100\n",
            "48/48 [==============================] - 20s 428ms/step - loss: 0.3961 - val_loss: 0.3894\n",
            "Epoch 17/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.3830 - val_loss: 0.3766\n",
            "Epoch 18/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.3704 - val_loss: 0.3642\n",
            "Epoch 19/100\n",
            "48/48 [==============================] - 21s 441ms/step - loss: 0.3583 - val_loss: 0.3524\n",
            "Epoch 20/100\n",
            "48/48 [==============================] - 19s 388ms/step - loss: 0.3467 - val_loss: 0.3410\n",
            "Epoch 21/100\n",
            "48/48 [==============================] - 18s 386ms/step - loss: 0.3355 - val_loss: 0.3301\n",
            "Epoch 22/100\n",
            "48/48 [==============================] - 20s 429ms/step - loss: 0.3248 - val_loss: 0.3196\n",
            "Epoch 23/100\n",
            "48/48 [==============================] - 19s 388ms/step - loss: 0.3145 - val_loss: 0.3095\n",
            "Epoch 24/100\n",
            "48/48 [==============================] - 18s 386ms/step - loss: 0.3046 - val_loss: 0.2998\n",
            "Epoch 25/100\n",
            "48/48 [==============================] - 21s 437ms/step - loss: 0.2951 - val_loss: 0.2905\n",
            "Epoch 26/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.2860 - val_loss: 0.2816\n",
            "Epoch 27/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.2772 - val_loss: 0.2730\n",
            "Epoch 28/100\n",
            "48/48 [==============================] - 21s 436ms/step - loss: 0.2688 - val_loss: 0.2648\n",
            "Epoch 29/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.2607 - val_loss: 0.2568\n",
            "Epoch 30/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.2529 - val_loss: 0.2492\n",
            "Epoch 31/100\n",
            "48/48 [==============================] - 20s 413ms/step - loss: 0.2454 - val_loss: 0.2418\n",
            "Epoch 32/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.2382 - val_loss: 0.2348\n",
            "Epoch 33/100\n",
            "48/48 [==============================] - 18s 386ms/step - loss: 0.2312 - val_loss: 0.2280\n",
            "Epoch 34/100\n",
            "48/48 [==============================] - 19s 397ms/step - loss: 0.2245 - val_loss: 0.2214\n",
            "Epoch 35/100\n",
            "48/48 [==============================] - 19s 400ms/step - loss: 0.2181 - val_loss: 0.2151\n",
            "Epoch 36/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.2119 - val_loss: 0.2090\n",
            "Epoch 37/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.2059 - val_loss: 0.2031\n",
            "Epoch 38/100\n",
            "48/48 [==============================] - 20s 423ms/step - loss: 0.2001 - val_loss: 0.1975\n",
            "Epoch 39/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.1946 - val_loss: 0.1920\n",
            "Epoch 40/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.1892 - val_loss: 0.1868\n",
            "Epoch 41/100\n",
            "48/48 [==============================] - 21s 438ms/step - loss: 0.1841 - val_loss: 0.1817\n",
            "Epoch 42/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.1791 - val_loss: 0.1768\n",
            "Epoch 43/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.1743 - val_loss: 0.1721\n",
            "Epoch 44/100\n",
            "48/48 [==============================] - 20s 417ms/step - loss: 0.1696 - val_loss: 0.1676\n",
            "Epoch 45/100\n",
            "48/48 [==============================] - 19s 385ms/step - loss: 0.1651 - val_loss: 0.1632\n",
            "Epoch 46/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.1608 - val_loss: 0.1589\n",
            "Epoch 47/100\n",
            "48/48 [==============================] - 20s 422ms/step - loss: 0.1566 - val_loss: 0.1548\n",
            "Epoch 48/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.1526 - val_loss: 0.1508\n",
            "Epoch 49/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.1487 - val_loss: 0.1470\n",
            "Epoch 50/100\n",
            "48/48 [==============================] - 21s 433ms/step - loss: 0.1449 - val_loss: 0.1433\n",
            "Epoch 51/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.1413 - val_loss: 0.1397\n",
            "Epoch 52/100\n",
            "48/48 [==============================] - 18s 387ms/step - loss: 0.1377 - val_loss: 0.1363\n",
            "Epoch 53/100\n",
            "48/48 [==============================] - 21s 439ms/step - loss: 0.1343 - val_loss: 0.1329\n",
            "Epoch 54/100\n",
            "48/48 [==============================] - 19s 393ms/step - loss: 0.1310 - val_loss: 0.1297\n",
            "Epoch 55/100\n",
            "48/48 [==============================] - 19s 392ms/step - loss: 0.1278 - val_loss: 0.1265\n",
            "Epoch 56/100\n",
            "48/48 [==============================] - 20s 427ms/step - loss: 0.1247 - val_loss: 0.1235\n",
            "Epoch 57/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.1217 - val_loss: 0.1205\n",
            "Epoch 58/100\n",
            "48/48 [==============================] - 19s 390ms/step - loss: 0.1188 - val_loss: 0.1177\n",
            "Epoch 59/100\n",
            "48/48 [==============================] - 20s 426ms/step - loss: 0.1160 - val_loss: 0.1149\n",
            "Epoch 60/100\n",
            "48/48 [==============================] - 19s 390ms/step - loss: 0.1133 - val_loss: 0.1123\n",
            "Epoch 61/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.1107 - val_loss: 0.1097\n",
            "Epoch 62/100\n",
            "48/48 [==============================] - 20s 418ms/step - loss: 0.1081 - val_loss: 0.1072\n",
            "Epoch 63/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.1056 - val_loss: 0.1047\n",
            "Epoch 64/100\n",
            "48/48 [==============================] - 19s 388ms/step - loss: 0.1032 - val_loss: 0.1024\n",
            "Epoch 65/100\n",
            "48/48 [==============================] - 21s 433ms/step - loss: 0.1009 - val_loss: 0.1001\n",
            "Epoch 66/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.0986 - val_loss: 0.0978\n",
            "Epoch 67/100\n",
            "48/48 [==============================] - 19s 390ms/step - loss: 0.0964 - val_loss: 0.0957\n",
            "Epoch 68/100\n",
            "48/48 [==============================] - 20s 418ms/step - loss: 0.0943 - val_loss: 0.0936\n",
            "Epoch 69/100\n",
            "48/48 [==============================] - 19s 402ms/step - loss: 0.0922 - val_loss: 0.0916\n",
            "Epoch 70/100\n",
            "48/48 [==============================] - 19s 394ms/step - loss: 0.0902 - val_loss: 0.0896\n",
            "Epoch 71/100\n",
            "48/48 [==============================] - 20s 426ms/step - loss: 0.0883 - val_loss: 0.0877\n",
            "Epoch 72/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.0864 - val_loss: 0.0858\n",
            "Epoch 73/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.0845 - val_loss: 0.0840\n",
            "Epoch 74/100\n",
            "48/48 [==============================] - 20s 417ms/step - loss: 0.0828 - val_loss: 0.0823\n",
            "Epoch 75/100\n",
            "48/48 [==============================] - 19s 398ms/step - loss: 0.0810 - val_loss: 0.0806\n",
            "Epoch 76/100\n",
            "48/48 [==============================] - 19s 393ms/step - loss: 0.0793 - val_loss: 0.0789\n",
            "Epoch 77/100\n",
            "48/48 [==============================] - 20s 418ms/step - loss: 0.0777 - val_loss: 0.0773\n",
            "Epoch 78/100\n",
            "48/48 [==============================] - 19s 396ms/step - loss: 0.0761 - val_loss: 0.0757\n",
            "Epoch 79/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.0746 - val_loss: 0.0742\n",
            "Epoch 80/100\n",
            "48/48 [==============================] - 20s 428ms/step - loss: 0.0731 - val_loss: 0.0727\n",
            "Epoch 81/100\n",
            "48/48 [==============================] - 19s 395ms/step - loss: 0.0716 - val_loss: 0.0713\n",
            "Epoch 82/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.0702 - val_loss: 0.0699\n",
            "Epoch 83/100\n",
            "48/48 [==============================] - 21s 436ms/step - loss: 0.0688 - val_loss: 0.0685\n",
            "Epoch 84/100\n",
            "48/48 [==============================] - 19s 393ms/step - loss: 0.0675 - val_loss: 0.0672\n",
            "Epoch 85/100\n",
            "48/48 [==============================] - 19s 394ms/step - loss: 0.0662 - val_loss: 0.0659\n",
            "Epoch 86/100\n",
            "48/48 [==============================] - 20s 424ms/step - loss: 0.0649 - val_loss: 0.0647\n",
            "Epoch 87/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.0637 - val_loss: 0.0635\n",
            "Epoch 88/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.0625 - val_loss: 0.0623\n",
            "Epoch 89/100\n",
            "48/48 [==============================] - 20s 422ms/step - loss: 0.0613 - val_loss: 0.0611\n",
            "Epoch 90/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.0602 - val_loss: 0.0600\n",
            "Epoch 91/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.0590 - val_loss: 0.0589\n",
            "Epoch 92/100\n",
            "48/48 [==============================] - 21s 429ms/step - loss: 0.0580 - val_loss: 0.0579\n",
            "Epoch 93/100\n",
            "48/48 [==============================] - 19s 388ms/step - loss: 0.0569 - val_loss: 0.0568\n",
            "Epoch 94/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.0559 - val_loss: 0.0558\n",
            "Epoch 95/100\n",
            "48/48 [==============================] - 21s 430ms/step - loss: 0.0549 - val_loss: 0.0549\n",
            "Epoch 96/100\n",
            "48/48 [==============================] - 19s 388ms/step - loss: 0.0539 - val_loss: 0.0539\n",
            "Epoch 97/100\n",
            "48/48 [==============================] - 19s 390ms/step - loss: 0.0530 - val_loss: 0.0530\n",
            "Epoch 98/100\n",
            "48/48 [==============================] - 21s 430ms/step - loss: 0.0521 - val_loss: 0.0521\n",
            "Epoch 99/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.0512 - val_loss: 0.0512\n",
            "Epoch 100/100\n",
            "48/48 [==============================] - 19s 397ms/step - loss: 0.0503 - val_loss: 0.0503\n",
            "2023-05-12 21:55:28.625733: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 21:55:28.627306: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 21:55:28.628742: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "14/14 [==============================] - 3s 158ms/step\n",
            "(436, 616) (436, 616)\n",
            "The ratio of abnormal events in the test set is: 0.0026063386155129272\n",
            "auc for MIST:  0.9549194403380669\n",
            "macro-f1: 0.05355597049720145\n",
            "micro-f1: 0.05479023168440827\n",
            "68  finished\n",
            "69  started\n",
            "2023-05-12 21:55:33.266847: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-12 21:55:34.534687: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-12 21:55:37.973514: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 21:55:37.975658: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 21:55:37.977656: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "Epoch 1/100\n",
            "2023-05-12 21:55:39.357711: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 21:55:39.360018: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 21:55:39.362087: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-05-12 21:55:41.131327: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 21:55:41.133718: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 21:55:41.135995: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "48/48 [==============================] - ETA: 0s - loss: 0.68142023-05-12 21:56:01.048874: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 21:56:01.050464: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 21:56:01.051920: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "48/48 [==============================] - 24s 406ms/step - loss: 0.6814 - val_loss: 0.6685\n",
            "Epoch 2/100\n",
            "48/48 [==============================] - 19s 397ms/step - loss: 0.6532 - val_loss: 0.6383\n",
            "Epoch 3/100\n",
            "48/48 [==============================] - 20s 419ms/step - loss: 0.6266 - val_loss: 0.6147\n",
            "Epoch 4/100\n",
            "48/48 [==============================] - 19s 388ms/step - loss: 0.6038 - val_loss: 0.5925\n",
            "Epoch 5/100\n",
            "48/48 [==============================] - 19s 390ms/step - loss: 0.5821 - val_loss: 0.5713\n",
            "Epoch 6/100\n",
            "48/48 [==============================] - 20s 429ms/step - loss: 0.5614 - val_loss: 0.5510\n",
            "Epoch 7/100\n",
            "48/48 [==============================] - 19s 393ms/step - loss: 0.5415 - val_loss: 0.5316\n",
            "Epoch 8/100\n",
            "48/48 [==============================] - 19s 396ms/step - loss: 0.5225 - val_loss: 0.5130\n",
            "Epoch 9/100\n",
            "48/48 [==============================] - 20s 427ms/step - loss: 0.5042 - val_loss: 0.4951\n",
            "Epoch 10/100\n",
            "48/48 [==============================] - 19s 396ms/step - loss: 0.4867 - val_loss: 0.4779\n",
            "Epoch 11/100\n",
            "48/48 [==============================] - 19s 402ms/step - loss: 0.4699 - val_loss: 0.4615\n",
            "Epoch 12/100\n",
            "48/48 [==============================] - 20s 421ms/step - loss: 0.4538 - val_loss: 0.4457\n",
            "Epoch 13/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.4383 - val_loss: 0.4306\n",
            "Epoch 14/100\n",
            "48/48 [==============================] - 19s 398ms/step - loss: 0.4235 - val_loss: 0.4161\n",
            "Epoch 15/100\n",
            "48/48 [==============================] - 20s 420ms/step - loss: 0.4093 - val_loss: 0.4021\n",
            "Epoch 16/100\n",
            "48/48 [==============================] - 19s 397ms/step - loss: 0.3956 - val_loss: 0.3888\n",
            "Epoch 17/100\n",
            "48/48 [==============================] - 20s 428ms/step - loss: 0.3825 - val_loss: 0.3759\n",
            "Epoch 18/100\n",
            "48/48 [==============================] - 20s 404ms/step - loss: 0.3699 - val_loss: 0.3636\n",
            "Epoch 19/100\n",
            "48/48 [==============================] - 19s 396ms/step - loss: 0.3579 - val_loss: 0.3518\n",
            "Epoch 20/100\n",
            "48/48 [==============================] - 20s 417ms/step - loss: 0.3463 - val_loss: 0.3405\n",
            "Epoch 21/100\n",
            "48/48 [==============================] - 19s 402ms/step - loss: 0.3352 - val_loss: 0.3296\n",
            "Epoch 22/100\n",
            "48/48 [==============================] - 19s 398ms/step - loss: 0.3245 - val_loss: 0.3191\n",
            "Epoch 23/100\n",
            "48/48 [==============================] - 21s 445ms/step - loss: 0.3142 - val_loss: 0.3091\n",
            "Epoch 24/100\n",
            "48/48 [==============================] - 19s 399ms/step - loss: 0.3044 - val_loss: 0.2994\n",
            "Epoch 25/100\n",
            "48/48 [==============================] - 19s 394ms/step - loss: 0.2949 - val_loss: 0.2901\n",
            "Epoch 26/100\n",
            "48/48 [==============================] - 21s 432ms/step - loss: 0.2858 - val_loss: 0.2812\n",
            "Epoch 27/100\n",
            "48/48 [==============================] - 19s 395ms/step - loss: 0.2771 - val_loss: 0.2727\n",
            "Epoch 28/100\n",
            "48/48 [==============================] - 19s 392ms/step - loss: 0.2687 - val_loss: 0.2644\n",
            "Epoch 29/100\n",
            "48/48 [==============================] - 21s 432ms/step - loss: 0.2606 - val_loss: 0.2565\n",
            "Epoch 30/100\n",
            "48/48 [==============================] - 19s 396ms/step - loss: 0.2528 - val_loss: 0.2489\n",
            "Epoch 31/100\n",
            "48/48 [==============================] - 19s 395ms/step - loss: 0.2453 - val_loss: 0.2416\n",
            "Epoch 32/100\n",
            "48/48 [==============================] - 21s 427ms/step - loss: 0.2382 - val_loss: 0.2345\n",
            "Epoch 33/100\n",
            "48/48 [==============================] - 19s 399ms/step - loss: 0.2312 - val_loss: 0.2277\n",
            "Epoch 34/100\n",
            "48/48 [==============================] - 20s 428ms/step - loss: 0.2246 - val_loss: 0.2212\n",
            "Epoch 35/100\n",
            "48/48 [==============================] - 20s 407ms/step - loss: 0.2181 - val_loss: 0.2149\n",
            "Epoch 36/100\n",
            "48/48 [==============================] - 19s 397ms/step - loss: 0.2120 - val_loss: 0.2088\n",
            "Epoch 37/100\n",
            "48/48 [==============================] - 21s 447ms/step - loss: 0.2060 - val_loss: 0.2030\n",
            "Epoch 38/100\n",
            "48/48 [==============================] - 20s 409ms/step - loss: 0.2003 - val_loss: 0.1973\n",
            "Epoch 39/100\n",
            "48/48 [==============================] - 19s 396ms/step - loss: 0.1947 - val_loss: 0.1919\n",
            "Epoch 40/100\n",
            "48/48 [==============================] - 21s 427ms/step - loss: 0.1894 - val_loss: 0.1867\n",
            "Epoch 41/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.1842 - val_loss: 0.1816\n",
            "Epoch 42/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.1793 - val_loss: 0.1767\n",
            "Epoch 43/100\n",
            "48/48 [==============================] - 20s 427ms/step - loss: 0.1745 - val_loss: 0.1720\n",
            "Epoch 44/100\n",
            "48/48 [==============================] - 19s 392ms/step - loss: 0.1699 - val_loss: 0.1675\n",
            "Epoch 45/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.1654 - val_loss: 0.1631\n",
            "Epoch 46/100\n",
            "48/48 [==============================] - 20s 429ms/step - loss: 0.1611 - val_loss: 0.1589\n",
            "Epoch 47/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.1569 - val_loss: 0.1548\n",
            "Epoch 48/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.1529 - val_loss: 0.1508\n",
            "Epoch 49/100\n",
            "48/48 [==============================] - 21s 434ms/step - loss: 0.1490 - val_loss: 0.1470\n",
            "Epoch 50/100\n",
            "48/48 [==============================] - 18s 386ms/step - loss: 0.1453 - val_loss: 0.1433\n",
            "Epoch 51/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.1416 - val_loss: 0.1397\n",
            "Epoch 52/100\n",
            "48/48 [==============================] - 20s 424ms/step - loss: 0.1381 - val_loss: 0.1363\n",
            "Epoch 53/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.1347 - val_loss: 0.1329\n",
            "Epoch 54/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.1314 - val_loss: 0.1297\n",
            "Epoch 55/100\n",
            "48/48 [==============================] - 20s 415ms/step - loss: 0.1282 - val_loss: 0.1266\n",
            "Epoch 56/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.1252 - val_loss: 0.1235\n",
            "Epoch 57/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.1222 - val_loss: 0.1206\n",
            "Epoch 58/100\n",
            "48/48 [==============================] - 20s 415ms/step - loss: 0.1193 - val_loss: 0.1178\n",
            "Epoch 59/100\n",
            "48/48 [==============================] - 19s 398ms/step - loss: 0.1165 - val_loss: 0.1150\n",
            "Epoch 60/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.1138 - val_loss: 0.1123\n",
            "Epoch 61/100\n",
            "48/48 [==============================] - 20s 417ms/step - loss: 0.1112 - val_loss: 0.1098\n",
            "Epoch 62/100\n",
            "48/48 [==============================] - 19s 390ms/step - loss: 0.1086 - val_loss: 0.1072\n",
            "Epoch 63/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.1061 - val_loss: 0.1048\n",
            "Epoch 64/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.1038 - val_loss: 0.1025\n",
            "Epoch 65/100\n",
            "48/48 [==============================] - 20s 412ms/step - loss: 0.1014 - val_loss: 0.1002\n",
            "Epoch 66/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.0992 - val_loss: 0.0980\n",
            "Epoch 67/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.0970 - val_loss: 0.0958\n",
            "Epoch 68/100\n",
            "48/48 [==============================] - 21s 433ms/step - loss: 0.0949 - val_loss: 0.0937\n",
            "Epoch 69/100\n",
            "48/48 [==============================] - 18s 386ms/step - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 70/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.0908 - val_loss: 0.0897\n",
            "Epoch 71/100\n",
            "48/48 [==============================] - 21s 439ms/step - loss: 0.0889 - val_loss: 0.0878\n",
            "Epoch 72/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.0870 - val_loss: 0.0860\n",
            "Epoch 73/100\n",
            "48/48 [==============================] - 18s 386ms/step - loss: 0.0852 - val_loss: 0.0842\n",
            "Epoch 74/100\n",
            "48/48 [==============================] - 21s 431ms/step - loss: 0.0834 - val_loss: 0.0824\n",
            "Epoch 75/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.0817 - val_loss: 0.0808\n",
            "Epoch 76/100\n",
            "48/48 [==============================] - 19s 388ms/step - loss: 0.0800 - val_loss: 0.0791\n",
            "Epoch 77/100\n",
            "48/48 [==============================] - 20s 424ms/step - loss: 0.0784 - val_loss: 0.0775\n",
            "Epoch 78/100\n",
            "48/48 [==============================] - 19s 385ms/step - loss: 0.0768 - val_loss: 0.0759\n",
            "Epoch 79/100\n",
            "48/48 [==============================] - 18s 386ms/step - loss: 0.0753 - val_loss: 0.0744\n",
            "Epoch 80/100\n",
            "48/48 [==============================] - 20s 417ms/step - loss: 0.0738 - val_loss: 0.0730\n",
            "Epoch 81/100\n",
            "48/48 [==============================] - 19s 385ms/step - loss: 0.0724 - val_loss: 0.0715\n",
            "Epoch 82/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.0710 - val_loss: 0.0701\n",
            "Epoch 83/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.0696 - val_loss: 0.0688\n",
            "Epoch 84/100\n",
            "48/48 [==============================] - 20s 410ms/step - loss: 0.0683 - val_loss: 0.0675\n",
            "Epoch 85/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.0670 - val_loss: 0.0662\n",
            "Epoch 86/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.0657 - val_loss: 0.0650\n",
            "Epoch 87/100\n",
            "48/48 [==============================] - 20s 423ms/step - loss: 0.0645 - val_loss: 0.0637\n",
            "Epoch 88/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.0633 - val_loss: 0.0626\n",
            "Epoch 89/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.0621 - val_loss: 0.0614\n",
            "Epoch 90/100\n",
            "48/48 [==============================] - 19s 407ms/step - loss: 0.0610 - val_loss: 0.0603\n",
            "Epoch 91/100\n",
            "48/48 [==============================] - 19s 392ms/step - loss: 0.0599 - val_loss: 0.0592\n",
            "Epoch 92/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.0588 - val_loss: 0.0582\n",
            "Epoch 93/100\n",
            "48/48 [==============================] - 18s 386ms/step - loss: 0.0578 - val_loss: 0.0571\n",
            "Epoch 94/100\n",
            "48/48 [==============================] - 20s 410ms/step - loss: 0.0568 - val_loss: 0.0561\n",
            "Epoch 95/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.0558 - val_loss: 0.0552\n",
            "Epoch 96/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.0548 - val_loss: 0.0542\n",
            "Epoch 97/100\n",
            "48/48 [==============================] - 21s 435ms/step - loss: 0.0539 - val_loss: 0.0533\n",
            "Epoch 98/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.0530 - val_loss: 0.0524\n",
            "Epoch 99/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.0521 - val_loss: 0.0515\n",
            "Epoch 100/100\n",
            "48/48 [==============================] - 20s 409ms/step - loss: 0.0512 - val_loss: 0.0507\n",
            "2023-05-12 22:28:05.159078: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 22:28:05.160704: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 22:28:05.162154: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "14/14 [==============================] - 3s 155ms/step\n",
            "(436, 616) (436, 616)\n",
            "The ratio of abnormal events in the test set is: 0.002945162635529608\n",
            "auc for MIST:  0.9558881192001046\n",
            "macro-f1: 0.062167916764205446\n",
            "micro-f1: 0.062760344348792\n",
            "69  finished\n",
            "70  started\n",
            "2023-05-12 22:28:09.654676: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-12 22:28:10.904885: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-12 22:28:15.645381: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 22:28:15.646932: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 22:28:15.648368: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "Epoch 1/100\n",
            "2023-05-12 22:28:16.724404: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 22:28:16.726162: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 22:28:16.727722: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-05-12 22:28:17.998623: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 22:28:18.000388: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 22:28:18.002224: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "48/48 [==============================] - ETA: 0s - loss: 0.68132023-05-12 22:28:37.732793: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 22:28:37.734563: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 22:28:37.736120: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "48/48 [==============================] - 23s 409ms/step - loss: 0.6813 - val_loss: 0.6683\n",
            "Epoch 2/100\n",
            "48/48 [==============================] - 21s 431ms/step - loss: 0.6535 - val_loss: 0.6390\n",
            "Epoch 3/100\n",
            "48/48 [==============================] - 19s 392ms/step - loss: 0.6273 - val_loss: 0.6153\n",
            "Epoch 4/100\n",
            "48/48 [==============================] - 19s 395ms/step - loss: 0.6043 - val_loss: 0.5930\n",
            "Epoch 5/100\n",
            "48/48 [==============================] - 21s 432ms/step - loss: 0.5825 - val_loss: 0.5717\n",
            "Epoch 6/100\n",
            "48/48 [==============================] - 19s 397ms/step - loss: 0.5617 - val_loss: 0.5513\n",
            "Epoch 7/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.5417 - val_loss: 0.5317\n",
            "Epoch 8/100\n",
            "48/48 [==============================] - 21s 429ms/step - loss: 0.5226 - val_loss: 0.5130\n",
            "Epoch 9/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.5042 - val_loss: 0.4950\n",
            "Epoch 10/100\n",
            "48/48 [==============================] - 19s 390ms/step - loss: 0.4866 - val_loss: 0.4778\n",
            "Epoch 11/100\n",
            "48/48 [==============================] - 20s 428ms/step - loss: 0.4697 - val_loss: 0.4612\n",
            "Epoch 12/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.4534 - val_loss: 0.4453\n",
            "Epoch 13/100\n",
            "48/48 [==============================] - 19s 388ms/step - loss: 0.4379 - val_loss: 0.4301\n",
            "Epoch 14/100\n",
            "48/48 [==============================] - 21s 441ms/step - loss: 0.4229 - val_loss: 0.4155\n",
            "Epoch 15/100\n",
            "48/48 [==============================] - 19s 396ms/step - loss: 0.4086 - val_loss: 0.4014\n",
            "Epoch 16/100\n",
            "48/48 [==============================] - 19s 395ms/step - loss: 0.3949 - val_loss: 0.3880\n",
            "Epoch 17/100\n",
            "48/48 [==============================] - 21s 447ms/step - loss: 0.3817 - val_loss: 0.3751\n",
            "Epoch 18/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.3690 - val_loss: 0.3626\n",
            "Epoch 19/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.3568 - val_loss: 0.3507\n",
            "Epoch 20/100\n",
            "48/48 [==============================] - 20s 423ms/step - loss: 0.3451 - val_loss: 0.3393\n",
            "Epoch 21/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.3339 - val_loss: 0.3283\n",
            "Epoch 22/100\n",
            "48/48 [==============================] - 18s 386ms/step - loss: 0.3232 - val_loss: 0.3178\n",
            "Epoch 23/100\n",
            "48/48 [==============================] - 20s 417ms/step - loss: 0.3128 - val_loss: 0.3076\n",
            "Epoch 24/100\n",
            "48/48 [==============================] - 19s 392ms/step - loss: 0.3029 - val_loss: 0.2979\n",
            "Epoch 25/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.2933 - val_loss: 0.2885\n",
            "Epoch 26/100\n",
            "48/48 [==============================] - 19s 397ms/step - loss: 0.2841 - val_loss: 0.2795\n",
            "Epoch 27/100\n",
            "48/48 [==============================] - 20s 407ms/step - loss: 0.2753 - val_loss: 0.2709\n",
            "Epoch 28/100\n",
            "48/48 [==============================] - 18s 387ms/step - loss: 0.2668 - val_loss: 0.2626\n",
            "Epoch 29/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.2587 - val_loss: 0.2546\n",
            "Epoch 30/100\n",
            "48/48 [==============================] - 20s 417ms/step - loss: 0.2508 - val_loss: 0.2469\n",
            "Epoch 31/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.2432 - val_loss: 0.2395\n",
            "Epoch 32/100\n",
            "48/48 [==============================] - 19s 388ms/step - loss: 0.2360 - val_loss: 0.2323\n",
            "Epoch 33/100\n",
            "48/48 [==============================] - 19s 399ms/step - loss: 0.2290 - val_loss: 0.2254\n",
            "Epoch 34/100\n",
            "48/48 [==============================] - 18s 378ms/step - loss: 0.2222 - val_loss: 0.2188\n",
            "Epoch 35/100\n",
            "48/48 [==============================] - 19s 396ms/step - loss: 0.2157 - val_loss: 0.2125\n",
            "Epoch 36/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.2095 - val_loss: 0.2063\n",
            "Epoch 37/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.2034 - val_loss: 0.2004\n",
            "Epoch 38/100\n",
            "48/48 [==============================] - 20s 409ms/step - loss: 0.1976 - val_loss: 0.1947\n",
            "Epoch 39/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.1920 - val_loss: 0.1892\n",
            "Epoch 40/100\n",
            "48/48 [==============================] - 20s 424ms/step - loss: 0.1866 - val_loss: 0.1839\n",
            "Epoch 41/100\n",
            "48/48 [==============================] - 19s 383ms/step - loss: 0.1814 - val_loss: 0.1788\n",
            "Epoch 42/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.1763 - val_loss: 0.1738\n",
            "Epoch 43/100\n",
            "48/48 [==============================] - 19s 407ms/step - loss: 0.1715 - val_loss: 0.1690\n",
            "Epoch 44/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.1668 - val_loss: 0.1644\n",
            "Epoch 45/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.1623 - val_loss: 0.1600\n",
            "Epoch 46/100\n",
            "48/48 [==============================] - 19s 400ms/step - loss: 0.1579 - val_loss: 0.1557\n",
            "Epoch 47/100\n",
            "48/48 [==============================] - 18s 378ms/step - loss: 0.1537 - val_loss: 0.1515\n",
            "Epoch 48/100\n",
            "48/48 [==============================] - 20s 415ms/step - loss: 0.1496 - val_loss: 0.1475\n",
            "Epoch 49/100\n",
            "48/48 [==============================] - 18s 378ms/step - loss: 0.1456 - val_loss: 0.1436\n",
            "Epoch 50/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.1418 - val_loss: 0.1399\n",
            "Epoch 51/100\n",
            "48/48 [==============================] - 19s 407ms/step - loss: 0.1381 - val_loss: 0.1362\n",
            "Epoch 52/100\n",
            "48/48 [==============================] - 18s 377ms/step - loss: 0.1345 - val_loss: 0.1327\n",
            "Epoch 53/100\n",
            "48/48 [==============================] - 20s 412ms/step - loss: 0.1311 - val_loss: 0.1293\n",
            "Epoch 54/100\n",
            "48/48 [==============================] - 18s 378ms/step - loss: 0.1277 - val_loss: 0.1260\n",
            "Epoch 55/100\n",
            "48/48 [==============================] - 18s 376ms/step - loss: 0.1245 - val_loss: 0.1228\n",
            "Epoch 56/100\n",
            "48/48 [==============================] - 19s 408ms/step - loss: 0.1213 - val_loss: 0.1197\n",
            "Epoch 57/100\n",
            "48/48 [==============================] - 18s 377ms/step - loss: 0.1183 - val_loss: 0.1168\n",
            "Epoch 58/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.1153 - val_loss: 0.1139\n",
            "Epoch 59/100\n",
            "48/48 [==============================] - 19s 405ms/step - loss: 0.1125 - val_loss: 0.1110\n",
            "Epoch 60/100\n",
            "48/48 [==============================] - 18s 376ms/step - loss: 0.1097 - val_loss: 0.1083\n",
            "Epoch 61/100\n",
            "48/48 [==============================] - 20s 409ms/step - loss: 0.1070 - val_loss: 0.1057\n",
            "Epoch 62/100\n",
            "48/48 [==============================] - 19s 385ms/step - loss: 0.1044 - val_loss: 0.1031\n",
            "Epoch 63/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.1019 - val_loss: 0.1006\n",
            "Epoch 64/100\n",
            "48/48 [==============================] - 19s 406ms/step - loss: 0.0995 - val_loss: 0.0982\n",
            "Epoch 65/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.0971 - val_loss: 0.0959\n",
            "Epoch 66/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.0948 - val_loss: 0.0936\n",
            "Epoch 67/100\n",
            "48/48 [==============================] - 19s 398ms/step - loss: 0.0926 - val_loss: 0.0914\n",
            "Epoch 68/100\n",
            "48/48 [==============================] - 18s 378ms/step - loss: 0.0904 - val_loss: 0.0893\n",
            "Epoch 69/100\n",
            "48/48 [==============================] - 20s 417ms/step - loss: 0.0883 - val_loss: 0.0872\n",
            "Epoch 70/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.0862 - val_loss: 0.0852\n",
            "Epoch 71/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.0843 - val_loss: 0.0832\n",
            "Epoch 72/100\n",
            "48/48 [==============================] - 20s 408ms/step - loss: 0.0823 - val_loss: 0.0813\n",
            "Epoch 73/100\n",
            "48/48 [==============================] - 18s 376ms/step - loss: 0.0805 - val_loss: 0.0795\n",
            "Epoch 74/100\n",
            "48/48 [==============================] - 20s 409ms/step - loss: 0.0786 - val_loss: 0.0777\n",
            "Epoch 75/100\n",
            "48/48 [==============================] - 18s 377ms/step - loss: 0.0769 - val_loss: 0.0760\n",
            "Epoch 76/100\n",
            "48/48 [==============================] - 18s 377ms/step - loss: 0.0751 - val_loss: 0.0743\n",
            "Epoch 77/100\n",
            "48/48 [==============================] - 19s 405ms/step - loss: 0.0735 - val_loss: 0.0726\n",
            "Epoch 78/100\n",
            "48/48 [==============================] - 18s 378ms/step - loss: 0.0718 - val_loss: 0.0710\n",
            "Epoch 79/100\n",
            "48/48 [==============================] - 18s 378ms/step - loss: 0.0703 - val_loss: 0.0694\n",
            "Epoch 80/100\n",
            "48/48 [==============================] - 19s 403ms/step - loss: 0.0687 - val_loss: 0.0679\n",
            "Epoch 81/100\n",
            "48/48 [==============================] - 18s 376ms/step - loss: 0.0672 - val_loss: 0.0665\n",
            "Epoch 82/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.0658 - val_loss: 0.0650\n",
            "Epoch 83/100\n",
            "48/48 [==============================] - 19s 397ms/step - loss: 0.0643 - val_loss: 0.0636\n",
            "Epoch 84/100\n",
            "48/48 [==============================] - 18s 377ms/step - loss: 0.0630 - val_loss: 0.0623\n",
            "Epoch 85/100\n",
            "48/48 [==============================] - 20s 417ms/step - loss: 0.0616 - val_loss: 0.0609\n",
            "Epoch 86/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.0603 - val_loss: 0.0596\n",
            "Epoch 87/100\n",
            "48/48 [==============================] - 18s 377ms/step - loss: 0.0590 - val_loss: 0.0584\n",
            "Epoch 88/100\n",
            "48/48 [==============================] - 19s 406ms/step - loss: 0.0578 - val_loss: 0.0572\n",
            "Epoch 89/100\n",
            "48/48 [==============================] - 18s 376ms/step - loss: 0.0566 - val_loss: 0.0560\n",
            "Epoch 90/100\n",
            "48/48 [==============================] - 19s 406ms/step - loss: 0.0554 - val_loss: 0.0548\n",
            "Epoch 91/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.0543 - val_loss: 0.0537\n",
            "Epoch 92/100\n",
            "48/48 [==============================] - 18s 377ms/step - loss: 0.0532 - val_loss: 0.0526\n",
            "Epoch 93/100\n",
            "48/48 [==============================] - 19s 406ms/step - loss: 0.0521 - val_loss: 0.0515\n",
            "Epoch 94/100\n",
            "48/48 [==============================] - 18s 378ms/step - loss: 0.0510 - val_loss: 0.0505\n",
            "Epoch 95/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.0500 - val_loss: 0.0495\n",
            "Epoch 96/100\n",
            "48/48 [==============================] - 20s 408ms/step - loss: 0.0490 - val_loss: 0.0485\n",
            "Epoch 97/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.0480 - val_loss: 0.0475\n",
            "Epoch 98/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.0471 - val_loss: 0.0466\n",
            "Epoch 99/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.0461 - val_loss: 0.0456\n",
            "Epoch 100/100\n",
            "48/48 [==============================] - 18s 377ms/step - loss: 0.0452 - val_loss: 0.0447\n",
            "2023-05-12 23:00:41.714484: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 23:00:41.716092: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 23:00:41.717697: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "14/14 [==============================] - 3s 157ms/step\n",
            "(436, 616) (436, 616)\n",
            "The ratio of abnormal events in the test set is: 0.0013255093530322888\n",
            "auc for MIST:  0.9307657892774588\n",
            "macro-f1: 0.01761952270527319\n",
            "micro-f1: 0.018810102504491177\n",
            "70  finished\n",
            "71  started\n",
            "2023-05-12 23:00:46.597782: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-12 23:00:47.826033: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-12 23:00:52.331648: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 23:00:52.333145: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 23:00:52.334578: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "Epoch 1/100\n",
            "2023-05-12 23:00:53.423067: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 23:00:53.424784: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 23:00:53.426340: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-05-12 23:00:54.690607: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 23:00:54.693193: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 23:00:54.695219: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "48/48 [==============================] - ETA: 0s - loss: 0.68142023-05-12 23:01:14.379139: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 23:01:14.380795: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 23:01:14.382260: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "48/48 [==============================] - 24s 431ms/step - loss: 0.6814 - val_loss: 0.6688\n",
            "Epoch 2/100\n",
            "48/48 [==============================] - 19s 385ms/step - loss: 0.6544 - val_loss: 0.6401\n",
            "Epoch 3/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.6284 - val_loss: 0.6165\n",
            "Epoch 4/100\n",
            "48/48 [==============================] - 20s 411ms/step - loss: 0.6055 - val_loss: 0.5943\n",
            "Epoch 5/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.5838 - val_loss: 0.5731\n",
            "Epoch 6/100\n",
            "48/48 [==============================] - 20s 413ms/step - loss: 0.5630 - val_loss: 0.5528\n",
            "Epoch 7/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.5431 - val_loss: 0.5333\n",
            "Epoch 8/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.5241 - val_loss: 0.5146\n",
            "Epoch 9/100\n",
            "48/48 [==============================] - 20s 413ms/step - loss: 0.5058 - val_loss: 0.4967\n",
            "Epoch 10/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.4882 - val_loss: 0.4796\n",
            "Epoch 11/100\n",
            "48/48 [==============================] - 20s 416ms/step - loss: 0.4714 - val_loss: 0.4631\n",
            "Epoch 12/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.4553 - val_loss: 0.4473\n",
            "Epoch 13/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.4398 - val_loss: 0.4322\n",
            "Epoch 14/100\n",
            "48/48 [==============================] - 20s 413ms/step - loss: 0.4249 - val_loss: 0.4177\n",
            "Epoch 15/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.4107 - val_loss: 0.4037\n",
            "Epoch 16/100\n",
            "48/48 [==============================] - 20s 426ms/step - loss: 0.3970 - val_loss: 0.3903\n",
            "Epoch 17/100\n",
            "48/48 [==============================] - 18s 387ms/step - loss: 0.3839 - val_loss: 0.3775\n",
            "Epoch 18/100\n",
            "48/48 [==============================] - 19s 388ms/step - loss: 0.3713 - val_loss: 0.3652\n",
            "Epoch 19/100\n",
            "48/48 [==============================] - 20s 406ms/step - loss: 0.3592 - val_loss: 0.3534\n",
            "Epoch 20/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.3476 - val_loss: 0.3420\n",
            "Epoch 21/100\n",
            "48/48 [==============================] - 20s 412ms/step - loss: 0.3364 - val_loss: 0.3311\n",
            "Epoch 22/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.3258 - val_loss: 0.3206\n",
            "Epoch 23/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.3155 - val_loss: 0.3106\n",
            "Epoch 24/100\n",
            "48/48 [==============================] - 20s 411ms/step - loss: 0.3056 - val_loss: 0.3009\n",
            "Epoch 25/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.2961 - val_loss: 0.2917\n",
            "Epoch 26/100\n",
            "48/48 [==============================] - 19s 406ms/step - loss: 0.2870 - val_loss: 0.2828\n",
            "Epoch 27/100\n",
            "48/48 [==============================] - 19s 388ms/step - loss: 0.2783 - val_loss: 0.2742\n",
            "Epoch 28/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.2699 - val_loss: 0.2660\n",
            "Epoch 29/100\n",
            "48/48 [==============================] - 20s 413ms/step - loss: 0.2618 - val_loss: 0.2580\n",
            "Epoch 30/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.2540 - val_loss: 0.2504\n",
            "Epoch 31/100\n",
            "48/48 [==============================] - 20s 417ms/step - loss: 0.2465 - val_loss: 0.2431\n",
            "Epoch 32/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.2393 - val_loss: 0.2360\n",
            "Epoch 33/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.2324 - val_loss: 0.2293\n",
            "Epoch 34/100\n",
            "48/48 [==============================] - 20s 411ms/step - loss: 0.2257 - val_loss: 0.2227\n",
            "Epoch 35/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.2193 - val_loss: 0.2164\n",
            "Epoch 36/100\n",
            "48/48 [==============================] - 20s 417ms/step - loss: 0.2131 - val_loss: 0.2104\n",
            "Epoch 37/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.2071 - val_loss: 0.2045\n",
            "Epoch 38/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.2014 - val_loss: 0.1989\n",
            "Epoch 39/100\n",
            "48/48 [==============================] - 20s 411ms/step - loss: 0.1959 - val_loss: 0.1935\n",
            "Epoch 40/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.1905 - val_loss: 0.1882\n",
            "Epoch 41/100\n",
            "48/48 [==============================] - 20s 416ms/step - loss: 0.1854 - val_loss: 0.1832\n",
            "Epoch 42/100\n",
            "48/48 [==============================] - 18s 377ms/step - loss: 0.1804 - val_loss: 0.1783\n",
            "Epoch 43/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.1756 - val_loss: 0.1736\n",
            "Epoch 44/100\n",
            "48/48 [==============================] - 20s 410ms/step - loss: 0.1710 - val_loss: 0.1691\n",
            "Epoch 45/100\n",
            "48/48 [==============================] - 18s 386ms/step - loss: 0.1665 - val_loss: 0.1647\n",
            "Epoch 46/100\n",
            "48/48 [==============================] - 19s 399ms/step - loss: 0.1622 - val_loss: 0.1605\n",
            "Epoch 47/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.1580 - val_loss: 0.1564\n",
            "Epoch 48/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.1540 - val_loss: 0.1524\n",
            "Epoch 49/100\n",
            "48/48 [==============================] - 20s 411ms/step - loss: 0.1501 - val_loss: 0.1486\n",
            "Epoch 50/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.1464 - val_loss: 0.1450\n",
            "Epoch 51/100\n",
            "48/48 [==============================] - 18s 386ms/step - loss: 0.1427 - val_loss: 0.1414\n",
            "Epoch 52/100\n",
            "48/48 [==============================] - 19s 399ms/step - loss: 0.1392 - val_loss: 0.1379\n",
            "Epoch 53/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.1358 - val_loss: 0.1346\n",
            "Epoch 54/100\n",
            "48/48 [==============================] - 20s 426ms/step - loss: 0.1325 - val_loss: 0.1314\n",
            "Epoch 55/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.1294 - val_loss: 0.1283\n",
            "Epoch 56/100\n",
            "48/48 [==============================] - 19s 386ms/step - loss: 0.1263 - val_loss: 0.1252\n",
            "Epoch 57/100\n",
            "48/48 [==============================] - 19s 403ms/step - loss: 0.1233 - val_loss: 0.1223\n",
            "Epoch 58/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.1204 - val_loss: 0.1195\n",
            "Epoch 59/100\n",
            "48/48 [==============================] - 20s 412ms/step - loss: 0.1176 - val_loss: 0.1167\n",
            "Epoch 60/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.1149 - val_loss: 0.1141\n",
            "Epoch 61/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.1123 - val_loss: 0.1115\n",
            "Epoch 62/100\n",
            "48/48 [==============================] - 20s 414ms/step - loss: 0.1098 - val_loss: 0.1090\n",
            "Epoch 63/100\n",
            "48/48 [==============================] - 19s 386ms/step - loss: 0.1073 - val_loss: 0.1066\n",
            "Epoch 64/100\n",
            "48/48 [==============================] - 20s 414ms/step - loss: 0.1049 - val_loss: 0.1043\n",
            "Epoch 65/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.1026 - val_loss: 0.1020\n",
            "Epoch 66/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.1003 - val_loss: 0.0998\n",
            "Epoch 67/100\n",
            "48/48 [==============================] - 20s 408ms/step - loss: 0.0982 - val_loss: 0.0976\n",
            "Epoch 68/100\n",
            "48/48 [==============================] - 19s 386ms/step - loss: 0.0961 - val_loss: 0.0956\n",
            "Epoch 69/100\n",
            "48/48 [==============================] - 20s 414ms/step - loss: 0.0940 - val_loss: 0.0936\n",
            "Epoch 70/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.0920 - val_loss: 0.0916\n",
            "Epoch 71/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.0901 - val_loss: 0.0897\n",
            "Epoch 72/100\n",
            "48/48 [==============================] - 20s 411ms/step - loss: 0.0882 - val_loss: 0.0879\n",
            "Epoch 73/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.0864 - val_loss: 0.0861\n",
            "Epoch 74/100\n",
            "48/48 [==============================] - 20s 417ms/step - loss: 0.0846 - val_loss: 0.0843\n",
            "Epoch 75/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.0829 - val_loss: 0.0827\n",
            "Epoch 76/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.0812 - val_loss: 0.0810\n",
            "Epoch 77/100\n",
            "48/48 [==============================] - 20s 413ms/step - loss: 0.0796 - val_loss: 0.0794\n",
            "Epoch 78/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.0780 - val_loss: 0.0779\n",
            "Epoch 79/100\n",
            "48/48 [==============================] - 20s 426ms/step - loss: 0.0765 - val_loss: 0.0764\n",
            "Epoch 80/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.0750 - val_loss: 0.0749\n",
            "Epoch 81/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.0736 - val_loss: 0.0735\n",
            "Epoch 82/100\n",
            "48/48 [==============================] - 20s 409ms/step - loss: 0.0722 - val_loss: 0.0721\n",
            "Epoch 83/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.0708 - val_loss: 0.0708\n",
            "Epoch 84/100\n",
            "48/48 [==============================] - 19s 403ms/step - loss: 0.0695 - val_loss: 0.0695\n",
            "Epoch 85/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.0682 - val_loss: 0.0682\n",
            "Epoch 86/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.0669 - val_loss: 0.0670\n",
            "Epoch 87/100\n",
            "48/48 [==============================] - 20s 413ms/step - loss: 0.0657 - val_loss: 0.0658\n",
            "Epoch 88/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.0645 - val_loss: 0.0646\n",
            "Epoch 89/100\n",
            "48/48 [==============================] - 20s 416ms/step - loss: 0.0634 - val_loss: 0.0635\n",
            "Epoch 90/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.0623 - val_loss: 0.0624\n",
            "Epoch 91/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.0612 - val_loss: 0.0613\n",
            "Epoch 92/100\n",
            "48/48 [==============================] - 20s 414ms/step - loss: 0.0601 - val_loss: 0.0603\n",
            "Epoch 93/100\n",
            "48/48 [==============================] - 19s 390ms/step - loss: 0.0591 - val_loss: 0.0593\n",
            "Epoch 94/100\n",
            "48/48 [==============================] - 21s 430ms/step - loss: 0.0580 - val_loss: 0.0583\n",
            "Epoch 95/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.0571 - val_loss: 0.0573\n",
            "Epoch 96/100\n",
            "48/48 [==============================] - 19s 390ms/step - loss: 0.0561 - val_loss: 0.0564\n",
            "Epoch 97/100\n",
            "48/48 [==============================] - 20s 404ms/step - loss: 0.0552 - val_loss: 0.0555\n",
            "Epoch 98/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.0543 - val_loss: 0.0546\n",
            "Epoch 99/100\n",
            "48/48 [==============================] - 20s 412ms/step - loss: 0.0534 - val_loss: 0.0537\n",
            "Epoch 100/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.0525 - val_loss: 0.0529\n",
            "2023-05-12 23:33:18.413115: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 23:33:18.414712: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 23:33:18.416193: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "14/14 [==============================] - 3s 157ms/step\n",
            "(436, 616) (436, 616)\n",
            "The ratio of abnormal events in the test set is: 0.003149946383891338\n",
            "auc for MIST:  0.9559817726814328\n",
            "macro-f1: 0.06637036327680212\n",
            "micro-f1: 0.06697806982820045\n",
            "71  finished\n",
            "72  started\n",
            "2023-05-12 23:33:22.960299: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-12 23:33:24.182341: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-12 23:33:28.235458: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 23:33:28.237534: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 23:33:28.239485: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "Epoch 1/100\n",
            "2023-05-12 23:33:29.512930: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 23:33:29.514643: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 23:33:29.516182: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-05-12 23:33:30.779059: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 23:33:30.780754: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 23:33:30.782411: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "48/48 [==============================] - ETA: 0s - loss: 0.68132023-05-12 23:33:49.967141: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-12 23:33:49.969152: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-12 23:33:49.970695: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "48/48 [==============================] - 22s 396ms/step - loss: 0.6813 - val_loss: 0.6685\n",
            "Epoch 2/100\n",
            "48/48 [==============================] - 19s 408ms/step - loss: 0.6539 - val_loss: 0.6391\n",
            "Epoch 3/100\n",
            "48/48 [==============================] - 18s 378ms/step - loss: 0.6273 - val_loss: 0.6152\n",
            "Epoch 4/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.6043 - val_loss: 0.5929\n",
            "Epoch 5/100\n",
            "48/48 [==============================] - 20s 409ms/step - loss: 0.5824 - val_loss: 0.5715\n",
            "Epoch 6/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.5616 - val_loss: 0.5511\n",
            "Epoch 7/100\n",
            "48/48 [==============================] - 20s 415ms/step - loss: 0.5415 - val_loss: 0.5315\n",
            "Epoch 8/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.5223 - val_loss: 0.5127\n",
            "Epoch 9/100\n",
            "48/48 [==============================] - 18s 386ms/step - loss: 0.5039 - val_loss: 0.4947\n",
            "Epoch 10/100\n",
            "48/48 [==============================] - 20s 409ms/step - loss: 0.4863 - val_loss: 0.4774\n",
            "Epoch 11/100\n",
            "48/48 [==============================] - 18s 378ms/step - loss: 0.4693 - val_loss: 0.4608\n",
            "Epoch 12/100\n",
            "48/48 [==============================] - 20s 411ms/step - loss: 0.4531 - val_loss: 0.4449\n",
            "Epoch 13/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.4375 - val_loss: 0.4296\n",
            "Epoch 14/100\n",
            "48/48 [==============================] - 18s 386ms/step - loss: 0.4225 - val_loss: 0.4150\n",
            "Epoch 15/100\n",
            "48/48 [==============================] - 20s 416ms/step - loss: 0.4081 - val_loss: 0.4009\n",
            "Epoch 16/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.3944 - val_loss: 0.3874\n",
            "Epoch 17/100\n",
            "48/48 [==============================] - 20s 415ms/step - loss: 0.3811 - val_loss: 0.3745\n",
            "Epoch 18/100\n",
            "48/48 [==============================] - 19s 386ms/step - loss: 0.3684 - val_loss: 0.3620\n",
            "Epoch 19/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.3562 - val_loss: 0.3501\n",
            "Epoch 20/100\n",
            "48/48 [==============================] - 20s 409ms/step - loss: 0.3445 - val_loss: 0.3386\n",
            "Epoch 21/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.3333 - val_loss: 0.3276\n",
            "Epoch 22/100\n",
            "48/48 [==============================] - 20s 422ms/step - loss: 0.3225 - val_loss: 0.3170\n",
            "Epoch 23/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.3121 - val_loss: 0.3068\n",
            "Epoch 24/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.3021 - val_loss: 0.2971\n",
            "Epoch 25/100\n",
            "48/48 [==============================] - 20s 409ms/step - loss: 0.2926 - val_loss: 0.2877\n",
            "Epoch 26/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.2833 - val_loss: 0.2787\n",
            "Epoch 27/100\n",
            "48/48 [==============================] - 19s 405ms/step - loss: 0.2745 - val_loss: 0.2700\n",
            "Epoch 28/100\n",
            "48/48 [==============================] - 19s 386ms/step - loss: 0.2660 - val_loss: 0.2616\n",
            "Epoch 29/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.2578 - val_loss: 0.2536\n",
            "Epoch 30/100\n",
            "48/48 [==============================] - 20s 409ms/step - loss: 0.2499 - val_loss: 0.2459\n",
            "Epoch 31/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.2423 - val_loss: 0.2384\n",
            "Epoch 32/100\n",
            "48/48 [==============================] - 18s 386ms/step - loss: 0.2350 - val_loss: 0.2313\n",
            "Epoch 33/100\n",
            "48/48 [==============================] - 19s 402ms/step - loss: 0.2280 - val_loss: 0.2244\n",
            "Epoch 34/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.2212 - val_loss: 0.2177\n",
            "Epoch 35/100\n",
            "48/48 [==============================] - 20s 417ms/step - loss: 0.2147 - val_loss: 0.2113\n",
            "Epoch 36/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.2084 - val_loss: 0.2052\n",
            "Epoch 37/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.2024 - val_loss: 0.1992\n",
            "Epoch 38/100\n",
            "48/48 [==============================] - 20s 409ms/step - loss: 0.1965 - val_loss: 0.1935\n",
            "Epoch 39/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.1909 - val_loss: 0.1879\n",
            "Epoch 40/100\n",
            "48/48 [==============================] - 20s 416ms/step - loss: 0.1854 - val_loss: 0.1826\n",
            "Epoch 41/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.1802 - val_loss: 0.1775\n",
            "Epoch 42/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.1751 - val_loss: 0.1725\n",
            "Epoch 43/100\n",
            "48/48 [==============================] - 20s 410ms/step - loss: 0.1703 - val_loss: 0.1677\n",
            "Epoch 44/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.1655 - val_loss: 0.1631\n",
            "Epoch 45/100\n",
            "48/48 [==============================] - 20s 412ms/step - loss: 0.1610 - val_loss: 0.1586\n",
            "Epoch 46/100\n",
            "48/48 [==============================] - 19s 383ms/step - loss: 0.1566 - val_loss: 0.1543\n",
            "Epoch 47/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.1523 - val_loss: 0.1501\n",
            "Epoch 48/100\n",
            "48/48 [==============================] - 20s 429ms/step - loss: 0.1482 - val_loss: 0.1460\n",
            "Epoch 49/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.1443 - val_loss: 0.1421\n",
            "Epoch 50/100\n",
            "48/48 [==============================] - 19s 402ms/step - loss: 0.1404 - val_loss: 0.1383\n",
            "Epoch 51/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.1367 - val_loss: 0.1347\n",
            "Epoch 52/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.1331 - val_loss: 0.1312\n",
            "Epoch 53/100\n",
            "48/48 [==============================] - 20s 413ms/step - loss: 0.1296 - val_loss: 0.1277\n",
            "Epoch 54/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.1262 - val_loss: 0.1244\n",
            "Epoch 55/100\n",
            "48/48 [==============================] - 20s 412ms/step - loss: 0.1230 - val_loss: 0.1212\n",
            "Epoch 56/100\n",
            "48/48 [==============================] - 19s 382ms/step - loss: 0.1198 - val_loss: 0.1181\n",
            "Epoch 57/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.1168 - val_loss: 0.1151\n",
            "Epoch 58/100\n",
            "48/48 [==============================] - 20s 410ms/step - loss: 0.1138 - val_loss: 0.1122\n",
            "Epoch 59/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.1109 - val_loss: 0.1093\n",
            "Epoch 60/100\n",
            "48/48 [==============================] - 20s 414ms/step - loss: 0.1081 - val_loss: 0.1066\n",
            "Epoch 61/100\n",
            "48/48 [==============================] - 19s 384ms/step - loss: 0.1054 - val_loss: 0.1039\n",
            "Epoch 62/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.1028 - val_loss: 0.1013\n",
            "Epoch 63/100\n",
            "48/48 [==============================] - 20s 409ms/step - loss: 0.1003 - val_loss: 0.0988\n",
            "Epoch 64/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.0978 - val_loss: 0.0964\n",
            "Epoch 65/100\n",
            "48/48 [==============================] - 19s 390ms/step - loss: 0.0954 - val_loss: 0.0940\n",
            "Epoch 66/100\n",
            "48/48 [==============================] - 19s 398ms/step - loss: 0.0931 - val_loss: 0.0918\n",
            "Epoch 67/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.0908 - val_loss: 0.0895\n",
            "Epoch 68/100\n",
            "48/48 [==============================] - 20s 428ms/step - loss: 0.0886 - val_loss: 0.0874\n",
            "Epoch 69/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.0865 - val_loss: 0.0853\n",
            "Epoch 70/100\n",
            "48/48 [==============================] - 20s 413ms/step - loss: 0.0845 - val_loss: 0.0832\n",
            "Epoch 71/100\n",
            "48/48 [==============================] - 19s 383ms/step - loss: 0.0825 - val_loss: 0.0813\n",
            "Epoch 72/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.0805 - val_loss: 0.0793\n",
            "Epoch 73/100\n",
            "48/48 [==============================] - 20s 410ms/step - loss: 0.0786 - val_loss: 0.0775\n",
            "Epoch 74/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.0768 - val_loss: 0.0757\n",
            "Epoch 75/100\n",
            "48/48 [==============================] - 20s 415ms/step - loss: 0.0750 - val_loss: 0.0739\n",
            "Epoch 76/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.0732 - val_loss: 0.0722\n",
            "Epoch 77/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.0716 - val_loss: 0.0705\n",
            "Epoch 78/100\n",
            "48/48 [==============================] - 20s 411ms/step - loss: 0.0699 - val_loss: 0.0689\n",
            "Epoch 79/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.0683 - val_loss: 0.0673\n",
            "Epoch 80/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.0667 - val_loss: 0.0658\n",
            "Epoch 81/100\n",
            "48/48 [==============================] - 20s 405ms/step - loss: 0.0652 - val_loss: 0.0643\n",
            "Epoch 82/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.0638 - val_loss: 0.0628\n",
            "Epoch 83/100\n",
            "48/48 [==============================] - 19s 406ms/step - loss: 0.0623 - val_loss: 0.0614\n",
            "Epoch 84/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.0609 - val_loss: 0.0600\n",
            "Epoch 85/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.0596 - val_loss: 0.0587\n",
            "Epoch 86/100\n",
            "48/48 [==============================] - 20s 412ms/step - loss: 0.0582 - val_loss: 0.0574\n",
            "Epoch 87/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.0570 - val_loss: 0.0561\n",
            "Epoch 88/100\n",
            "48/48 [==============================] - 20s 415ms/step - loss: 0.0557 - val_loss: 0.0549\n",
            "Epoch 89/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.0545 - val_loss: 0.0537\n",
            "Epoch 90/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.0533 - val_loss: 0.0525\n",
            "Epoch 91/100\n",
            "48/48 [==============================] - 20s 410ms/step - loss: 0.0521 - val_loss: 0.0513\n",
            "Epoch 92/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.0510 - val_loss: 0.0502\n",
            "Epoch 93/100\n",
            "48/48 [==============================] - 20s 414ms/step - loss: 0.0499 - val_loss: 0.0491\n",
            "Epoch 94/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.0488 - val_loss: 0.0481\n",
            "Epoch 95/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.0478 - val_loss: 0.0470\n",
            "Epoch 96/100\n",
            "48/48 [==============================] - 20s 412ms/step - loss: 0.0468 - val_loss: 0.0460\n",
            "Epoch 97/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.0458 - val_loss: 0.0450\n",
            "Epoch 98/100\n",
            "48/48 [==============================] - 20s 412ms/step - loss: 0.0448 - val_loss: 0.0441\n",
            "Epoch 99/100\n",
            "48/48 [==============================] - 19s 382ms/step - loss: 0.0438 - val_loss: 0.0431\n",
            "Epoch 100/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.0429 - val_loss: 0.0422\n",
            "2023-05-13 00:05:02.362437: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-13 00:05:02.364307: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-13 00:05:02.365830: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "14/14 [==============================] - 4s 239ms/step\n",
            "(435, 616) (435, 616)\n",
            "The ratio of abnormal events in the test set is: 0.00054858934169279\n",
            "auc for MIST:  0.9060669198283877\n",
            "macro-f1: 0.005351718836581337\n",
            "micro-f1: 0.005809472997806628\n",
            "72  finished\n",
            "73  started\n",
            "2023-05-13 00:05:09.778163: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-13 00:05:11.031706: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-13 00:05:14.468221: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-13 00:05:14.470529: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-13 00:05:14.472616: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "Epoch 1/100\n",
            "2023-05-13 00:05:15.573823: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-13 00:05:15.575571: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-13 00:05:15.577156: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-05-13 00:05:17.055639: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-13 00:05:17.058010: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-13 00:05:17.060358: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "48/48 [==============================] - ETA: 0s - loss: 0.68132023-05-13 00:05:37.476979: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-13 00:05:37.478632: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-13 00:05:37.480145: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "48/48 [==============================] - 24s 403ms/step - loss: 0.6813 - val_loss: 0.6684\n",
            "Epoch 2/100\n",
            "48/48 [==============================] - 19s 401ms/step - loss: 0.6533 - val_loss: 0.6383\n",
            "Epoch 3/100\n",
            "48/48 [==============================] - 20s 407ms/step - loss: 0.6265 - val_loss: 0.6145\n",
            "Epoch 4/100\n",
            "48/48 [==============================] - 19s 393ms/step - loss: 0.6036 - val_loss: 0.5922\n",
            "Epoch 5/100\n",
            "48/48 [==============================] - 20s 424ms/step - loss: 0.5818 - val_loss: 0.5710\n",
            "Epoch 6/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.5610 - val_loss: 0.5507\n",
            "Epoch 7/100\n",
            "48/48 [==============================] - 20s 429ms/step - loss: 0.5411 - val_loss: 0.5312\n",
            "Epoch 8/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.5220 - val_loss: 0.5125\n",
            "Epoch 9/100\n",
            "48/48 [==============================] - 20s 424ms/step - loss: 0.5036 - val_loss: 0.4945\n",
            "Epoch 10/100\n",
            "48/48 [==============================] - 19s 392ms/step - loss: 0.4861 - val_loss: 0.4773\n",
            "Epoch 11/100\n",
            "48/48 [==============================] - 19s 392ms/step - loss: 0.4692 - val_loss: 0.4608\n",
            "Epoch 12/100\n",
            "48/48 [==============================] - 20s 417ms/step - loss: 0.4530 - val_loss: 0.4450\n",
            "Epoch 13/100\n",
            "48/48 [==============================] - 19s 392ms/step - loss: 0.4375 - val_loss: 0.4298\n",
            "Epoch 14/100\n",
            "48/48 [==============================] - 20s 417ms/step - loss: 0.4226 - val_loss: 0.4152\n",
            "Epoch 15/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.4083 - val_loss: 0.4012\n",
            "Epoch 16/100\n",
            "48/48 [==============================] - 19s 394ms/step - loss: 0.3946 - val_loss: 0.3878\n",
            "Epoch 17/100\n",
            "48/48 [==============================] - 20s 410ms/step - loss: 0.3814 - val_loss: 0.3749\n",
            "Epoch 18/100\n",
            "48/48 [==============================] - 19s 388ms/step - loss: 0.3688 - val_loss: 0.3625\n",
            "Epoch 19/100\n",
            "48/48 [==============================] - 20s 415ms/step - loss: 0.3567 - val_loss: 0.3507\n",
            "Epoch 20/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.3450 - val_loss: 0.3393\n",
            "Epoch 21/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.3338 - val_loss: 0.3283\n",
            "Epoch 22/100\n",
            "48/48 [==============================] - 20s 406ms/step - loss: 0.3231 - val_loss: 0.3178\n",
            "Epoch 23/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.3128 - val_loss: 0.3077\n",
            "Epoch 24/100\n",
            "48/48 [==============================] - 20s 415ms/step - loss: 0.3029 - val_loss: 0.2980\n",
            "Epoch 25/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.2934 - val_loss: 0.2887\n",
            "Epoch 26/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.2842 - val_loss: 0.2797\n",
            "Epoch 27/100\n",
            "48/48 [==============================] - 20s 413ms/step - loss: 0.2754 - val_loss: 0.2711\n",
            "Epoch 28/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.2669 - val_loss: 0.2628\n",
            "Epoch 29/100\n",
            "48/48 [==============================] - 20s 428ms/step - loss: 0.2588 - val_loss: 0.2548\n",
            "Epoch 30/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.2510 - val_loss: 0.2472\n",
            "Epoch 31/100\n",
            "48/48 [==============================] - 19s 396ms/step - loss: 0.2435 - val_loss: 0.2398\n",
            "Epoch 32/100\n",
            "48/48 [==============================] - 19s 399ms/step - loss: 0.2362 - val_loss: 0.2327\n",
            "Epoch 33/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.2292 - val_loss: 0.2258\n",
            "Epoch 34/100\n",
            "48/48 [==============================] - 20s 415ms/step - loss: 0.2225 - val_loss: 0.2192\n",
            "Epoch 35/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.2161 - val_loss: 0.2129\n",
            "Epoch 36/100\n",
            "48/48 [==============================] - 20s 418ms/step - loss: 0.2098 - val_loss: 0.2068\n",
            "Epoch 37/100\n",
            "48/48 [==============================] - 19s 383ms/step - loss: 0.2038 - val_loss: 0.2009\n",
            "Epoch 38/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.1980 - val_loss: 0.1952\n",
            "Epoch 39/100\n",
            "48/48 [==============================] - 20s 415ms/step - loss: 0.1924 - val_loss: 0.1897\n",
            "Epoch 40/100\n",
            "48/48 [==============================] - 19s 388ms/step - loss: 0.1871 - val_loss: 0.1845\n",
            "Epoch 41/100\n",
            "48/48 [==============================] - 21s 435ms/step - loss: 0.1819 - val_loss: 0.1794\n",
            "Epoch 42/100\n",
            "48/48 [==============================] - 18s 386ms/step - loss: 0.1768 - val_loss: 0.1744\n",
            "Epoch 43/100\n",
            "48/48 [==============================] - 19s 395ms/step - loss: 0.1720 - val_loss: 0.1697\n",
            "Epoch 44/100\n",
            "48/48 [==============================] - 19s 400ms/step - loss: 0.1673 - val_loss: 0.1651\n",
            "Epoch 45/100\n",
            "48/48 [==============================] - 18s 386ms/step - loss: 0.1628 - val_loss: 0.1607\n",
            "Epoch 46/100\n",
            "48/48 [==============================] - 20s 418ms/step - loss: 0.1585 - val_loss: 0.1564\n",
            "Epoch 47/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.1543 - val_loss: 0.1523\n",
            "Epoch 48/100\n",
            "48/48 [==============================] - 19s 404ms/step - loss: 0.1502 - val_loss: 0.1483\n",
            "Epoch 49/100\n",
            "48/48 [==============================] - 19s 396ms/step - loss: 0.1463 - val_loss: 0.1444\n",
            "Epoch 50/100\n",
            "48/48 [==============================] - 19s 390ms/step - loss: 0.1425 - val_loss: 0.1407\n",
            "Epoch 51/100\n",
            "48/48 [==============================] - 20s 414ms/step - loss: 0.1388 - val_loss: 0.1371\n",
            "Epoch 52/100\n",
            "48/48 [==============================] - 19s 388ms/step - loss: 0.1352 - val_loss: 0.1336\n",
            "Epoch 53/100\n",
            "48/48 [==============================] - 20s 419ms/step - loss: 0.1318 - val_loss: 0.1302\n",
            "Epoch 54/100\n",
            "48/48 [==============================] - 19s 388ms/step - loss: 0.1284 - val_loss: 0.1269\n",
            "Epoch 55/100\n",
            "48/48 [==============================] - 19s 391ms/step - loss: 0.1252 - val_loss: 0.1237\n",
            "Epoch 56/100\n",
            "48/48 [==============================] - 20s 406ms/step - loss: 0.1221 - val_loss: 0.1207\n",
            "Epoch 57/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.1191 - val_loss: 0.1177\n",
            "Epoch 58/100\n",
            "48/48 [==============================] - 20s 416ms/step - loss: 0.1161 - val_loss: 0.1148\n",
            "Epoch 59/100\n",
            "48/48 [==============================] - 18s 383ms/step - loss: 0.1133 - val_loss: 0.1120\n",
            "Epoch 60/100\n",
            "48/48 [==============================] - 20s 413ms/step - loss: 0.1106 - val_loss: 0.1093\n",
            "Epoch 61/100\n",
            "48/48 [==============================] - 19s 384ms/step - loss: 0.1079 - val_loss: 0.1067\n",
            "Epoch 62/100\n",
            "48/48 [==============================] - 19s 390ms/step - loss: 0.1053 - val_loss: 0.1042\n",
            "Epoch 63/100\n",
            "48/48 [==============================] - 20s 415ms/step - loss: 0.1028 - val_loss: 0.1017\n",
            "Epoch 64/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.1004 - val_loss: 0.0993\n",
            "Epoch 65/100\n",
            "48/48 [==============================] - 20s 423ms/step - loss: 0.0980 - val_loss: 0.0970\n",
            "Epoch 66/100\n",
            "48/48 [==============================] - 18s 385ms/step - loss: 0.0957 - val_loss: 0.0947\n",
            "Epoch 67/100\n",
            "48/48 [==============================] - 19s 388ms/step - loss: 0.0935 - val_loss: 0.0925\n",
            "Epoch 68/100\n",
            "48/48 [==============================] - 20s 404ms/step - loss: 0.0914 - val_loss: 0.0904\n",
            "Epoch 69/100\n",
            "48/48 [==============================] - 18s 384ms/step - loss: 0.0893 - val_loss: 0.0884\n",
            "Epoch 70/100\n",
            "48/48 [==============================] - 20s 412ms/step - loss: 0.0872 - val_loss: 0.0864\n",
            "Epoch 71/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.0853 - val_loss: 0.0844\n",
            "Epoch 72/100\n",
            "48/48 [==============================] - 20s 421ms/step - loss: 0.0833 - val_loss: 0.0825\n",
            "Epoch 73/100\n",
            "48/48 [==============================] - 19s 385ms/step - loss: 0.0815 - val_loss: 0.0807\n",
            "Epoch 74/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.0797 - val_loss: 0.0789\n",
            "Epoch 75/100\n",
            "48/48 [==============================] - 20s 414ms/step - loss: 0.0779 - val_loss: 0.0772\n",
            "Epoch 76/100\n",
            "48/48 [==============================] - 18s 386ms/step - loss: 0.0762 - val_loss: 0.0755\n",
            "Epoch 77/100\n",
            "48/48 [==============================] - 21s 435ms/step - loss: 0.0745 - val_loss: 0.0739\n",
            "Epoch 78/100\n",
            "48/48 [==============================] - 19s 393ms/step - loss: 0.0729 - val_loss: 0.0723\n",
            "Epoch 79/100\n",
            "48/48 [==============================] - 20s 414ms/step - loss: 0.0714 - val_loss: 0.0707\n",
            "Epoch 80/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.0698 - val_loss: 0.0692\n",
            "Epoch 81/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.0684 - val_loss: 0.0678\n",
            "Epoch 82/100\n",
            "48/48 [==============================] - 20s 413ms/step - loss: 0.0669 - val_loss: 0.0664\n",
            "Epoch 83/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.0655 - val_loss: 0.0650\n",
            "Epoch 84/100\n",
            "48/48 [==============================] - 20s 410ms/step - loss: 0.0641 - val_loss: 0.0636\n",
            "Epoch 85/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.0628 - val_loss: 0.0623\n",
            "Epoch 86/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.0615 - val_loss: 0.0610\n",
            "Epoch 87/100\n",
            "48/48 [==============================] - 19s 407ms/step - loss: 0.0603 - val_loss: 0.0598\n",
            "Epoch 88/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.0590 - val_loss: 0.0586\n",
            "Epoch 89/100\n",
            "48/48 [==============================] - 20s 410ms/step - loss: 0.0578 - val_loss: 0.0574\n",
            "Epoch 90/100\n",
            "48/48 [==============================] - 18s 376ms/step - loss: 0.0567 - val_loss: 0.0563\n",
            "Epoch 91/100\n",
            "48/48 [==============================] - 18s 374ms/step - loss: 0.0555 - val_loss: 0.0552\n",
            "Epoch 92/100\n",
            "48/48 [==============================] - 19s 402ms/step - loss: 0.0544 - val_loss: 0.0541\n",
            "Epoch 93/100\n",
            "48/48 [==============================] - 18s 375ms/step - loss: 0.0534 - val_loss: 0.0530\n",
            "Epoch 94/100\n",
            "48/48 [==============================] - 18s 379ms/step - loss: 0.0523 - val_loss: 0.0520\n",
            "Epoch 95/100\n",
            "48/48 [==============================] - 19s 405ms/step - loss: 0.0513 - val_loss: 0.0510\n",
            "Epoch 96/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.0503 - val_loss: 0.0500\n",
            "Epoch 97/100\n",
            "48/48 [==============================] - 19s 408ms/step - loss: 0.0493 - val_loss: 0.0491\n",
            "Epoch 98/100\n",
            "48/48 [==============================] - 18s 376ms/step - loss: 0.0484 - val_loss: 0.0481\n",
            "Epoch 99/100\n",
            "48/48 [==============================] - 18s 378ms/step - loss: 0.0475 - val_loss: 0.0472\n",
            "Epoch 100/100\n",
            "48/48 [==============================] - 20s 412ms/step - loss: 0.0466 - val_loss: 0.0463\n",
            "2023-05-13 00:37:41.474515: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-13 00:37:41.476130: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-13 00:37:41.477632: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "14/14 [==============================] - 3s 161ms/step\n",
            "(436, 616) (436, 616)\n",
            "The ratio of abnormal events in the test set is: 0.0016308233051352317\n",
            "auc for MIST:  0.9487838351893427\n",
            "macro-f1: 0.03075119742336032\n",
            "micro-f1: 0.03090819278808835\n",
            "73  finished\n",
            "74  started\n",
            "2023-05-13 00:37:46.310670: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-13 00:37:47.535084: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-13 00:37:51.532298: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-13 00:37:51.534459: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-13 00:37:51.536376: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "Epoch 1/100\n",
            "2023-05-13 00:37:52.954693: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-13 00:37:52.956494: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-13 00:37:52.958109: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-05-13 00:37:54.236975: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-13 00:37:54.238760: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-13 00:37:54.240417: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "48/48 [==============================] - ETA: 0s - loss: 0.68142023-05-13 00:38:13.803199: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-13 00:38:13.804797: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-13 00:38:13.806255: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "48/48 [==============================] - 23s 407ms/step - loss: 0.6814 - val_loss: 0.6685\n",
            "Epoch 2/100\n",
            "48/48 [==============================] - 20s 412ms/step - loss: 0.6535 - val_loss: 0.6384\n",
            "Epoch 3/100\n",
            "48/48 [==============================] - 18s 386ms/step - loss: 0.6266 - val_loss: 0.6145\n",
            "Epoch 4/100\n",
            "48/48 [==============================] - 20s 419ms/step - loss: 0.6036 - val_loss: 0.5922\n",
            "Epoch 5/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.5817 - val_loss: 0.5708\n",
            "Epoch 6/100\n",
            "48/48 [==============================] - 18s 378ms/step - loss: 0.5608 - val_loss: 0.5504\n",
            "Epoch 7/100\n",
            "48/48 [==============================] - 19s 406ms/step - loss: 0.5408 - val_loss: 0.5309\n",
            "Epoch 8/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.5216 - val_loss: 0.5121\n",
            "Epoch 9/100\n",
            "48/48 [==============================] - 20s 424ms/step - loss: 0.5032 - val_loss: 0.4941\n",
            "Epoch 10/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.4856 - val_loss: 0.4768\n",
            "Epoch 11/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.4686 - val_loss: 0.4602\n",
            "Epoch 12/100\n",
            "48/48 [==============================] - 19s 407ms/step - loss: 0.4524 - val_loss: 0.4443\n",
            "Epoch 13/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.4368 - val_loss: 0.4290\n",
            "Epoch 14/100\n",
            "48/48 [==============================] - 19s 401ms/step - loss: 0.4218 - val_loss: 0.4144\n",
            "Epoch 15/100\n",
            "48/48 [==============================] - 19s 389ms/step - loss: 0.4075 - val_loss: 0.4003\n",
            "Epoch 16/100\n",
            "48/48 [==============================] - 18s 386ms/step - loss: 0.3937 - val_loss: 0.3868\n",
            "Epoch 17/100\n",
            "48/48 [==============================] - 20s 411ms/step - loss: 0.3805 - val_loss: 0.3739\n",
            "Epoch 18/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.3678 - val_loss: 0.3615\n",
            "Epoch 19/100\n",
            "48/48 [==============================] - 19s 398ms/step - loss: 0.3556 - val_loss: 0.3495\n",
            "Epoch 20/100\n",
            "48/48 [==============================] - 19s 387ms/step - loss: 0.3438 - val_loss: 0.3381\n",
            "Epoch 21/100\n",
            "48/48 [==============================] - 18s 380ms/step - loss: 0.3326 - val_loss: 0.3271\n",
            "Epoch 22/100\n",
            "48/48 [==============================] - 20s 412ms/step - loss: 0.3218 - val_loss: 0.3165\n",
            "Epoch 23/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.3114 - val_loss: 0.3063\n",
            "Epoch 24/100\n",
            "48/48 [==============================] - 20s 413ms/step - loss: 0.3015 - val_loss: 0.2966\n",
            "Epoch 25/100\n",
            "48/48 [==============================] - 18s 381ms/step - loss: 0.2919 - val_loss: 0.2872\n",
            "Epoch 26/100\n",
            "48/48 [==============================] - 18s 382ms/step - loss: 0.2827 - val_loss: 0.2781\n",
            "Epoch 27/100\n",
            "48/48 [==============================] - 19s 406ms/step - loss: 0.2738 - val_loss: 0.2695\n",
            "Epoch 28/100\n",
            "25/48 [==============>...............] - ETA: 7s - loss: 0.2673"
          ]
        }
      ],
      "source": [
        "for i in range(66, 78):\n",
        "  print(i, \" started\")\n",
        "  !python /content/Mist.py --tr=$i --epoch=100\n",
        "  print(i, \" finished\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-Wuns8j_o2T",
        "outputId": "d9fbf8b2-329e-4163-f733-acb5a7dfdc2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-09 14:39:30.537978: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-09 14:39:31.923315: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-09 14:39:35.818096: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-09 14:39:35.820326: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-09 14:39:35.822389: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "2023-05-09 14:39:37.087450: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-09 14:39:37.090678: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-09 14:39:37.094075: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-05-09 14:39:39.062903: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-09 14:39:39.064724: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-09 14:39:39.066790: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.24922023-05-09 14:39:44.055438: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-09 14:39:44.057161: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-09 14:39:44.060717: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "8/8 [==============================] - 8s 486ms/step - loss: 0.2492 - val_loss: 0.2480\n",
            "2023-05-09 14:39:45.120914: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-05-09 14:39:45.122687: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-05-09 14:39:45.124306: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "3/3 [==============================] - 1s 98ms/step\n",
            "(71, 616) (71, 616)\n",
            "The ratio of abnormal events in the test set is: 0.007225169197000183\n",
            "mae before threshold: 0.03769612526008323\n",
            "mse before threshold 0.005537651390660413\n",
            "mae after threshold: 0.9294402780318274\n",
            "mse after threshold 0.9294402780318274\n"
          ]
        }
      ],
      "source": [
        "!python /content/Mist.py --tr=1 --epoch=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Se-7jyXmrn7O"
      },
      "outputs": [],
      "source": [
        "# for CLASSIFICATION\n",
        "\n",
        "import os\n",
        "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
        "\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import time\n",
        "import sklearn\n",
        "from sklearn.utils.extmath import softmax\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, RepeatVector, Permute, Concatenate, Reshape, Softmax, Multiply, TimeDistributed, Flatten\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "import keras.backend as K\n",
        "import argparse\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc, roc_auc_score\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "import matplotlib.pyplot as plt\n",
        "# from keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "import sys\n",
        "import argparse as Ap\n",
        "argp = Ap.ArgumentParser()\n",
        "argp.add_argument(\"--tr\", default=25, type=int, help=\"Target region\")\n",
        "argp.add_argument(\"--epoch\", default=150, type=int, help=\"Epoch\")\n",
        "d = argp.parse_args(sys.argv[1:])\n",
        "\n",
        "tr = d.tr\n",
        "epoch = d.epoch\n",
        "\n",
        "# def emb(dim_input, dim_emb):\n",
        "def sigmoid(array):\n",
        "    for i in range(len(array)):\n",
        "        for j in range(len(array[i])):\n",
        "            # print(\"a :\", array[i][j])\n",
        "            array[i][j] = 1/(1 + np.exp(-array[i][j]))\n",
        "            # print(\"b :\", array[i][j])\n",
        "    return array\n",
        "\n",
        "# num_locations = 113\n",
        "num_locations = 77\n",
        "#77 for Chi and 113 for LA\n",
        "\n",
        "num_categories = 8\n",
        "num_timeslots = 8\n",
        "\n",
        "num_embed_loc = 4\n",
        "# num_embed_cat = 16\n",
        "\n",
        "# for chi\n",
        "num_embed_cat = 8\n",
        "\n",
        "lstm_dim = 32\n",
        "\n",
        "# build lstm\n",
        "event_input = Input(shape=(num_timeslots, num_locations * num_categories), name=\"event_input\")\n",
        "local_layer = Permute((2,1))(event_input)\n",
        "local_layer = Reshape((num_locations * num_categories, num_timeslots, 1))(local_layer)\n",
        "lstm = TimeDistributed(LSTM(lstm_dim))\n",
        "encoder_outputs = lstm(local_layer) # expected shape(num_locations * num_categories, lstm_dim)\n",
        "# lstm = LSTM(lstm_dim, return_state=True)\n",
        "# encoder_outputs, state_h, state_c = lstm(event_input)\n",
        "state_h = Reshape((num_locations, num_categories, lstm_dim))(encoder_outputs)\n",
        "\n",
        "# prepare embeddings, here we assume embeddings are learnable\n",
        "#loc_emb_input = Input(shape=(num_locations, num_locations), name=\"loc_emb_input\")\n",
        "# loc_emb_input = Input(shape=(num_locations, 16), name=\"loc_emb_input\")\n",
        "loc_emb_input = Input(shape=(num_locations, 8), name=\"loc_emb_input\")\n",
        "\n",
        "cat_emb_input = Input(shape=(num_categories, num_categories), name=\"cat_emb_input\")\n",
        "loc_emb = Dense(num_embed_loc, name = 'loc_emb_dense')(loc_emb_input)\n",
        "cat_emb = Dense(num_embed_cat, name = 'cat_emb_dense')(cat_emb_input)\n",
        "loc_emb = Flatten()(loc_emb)\n",
        "cat_emb = Flatten()(cat_emb)\n",
        "# loc_emb_input = Input(shape = (num_locations, num_embed_loc), name = \"loc_emb_input\")\n",
        "# cat_emb_input = Input(shape = (num_categories, num_embed_cat), name = \"cat_emb_input\")\n",
        "loc_emb = RepeatVector(num_categories)(loc_emb)\n",
        "loc_emb = Reshape((num_categories, num_locations, num_embed_loc))(loc_emb) # shape(num_categories, num_locations, num_embed_loc)\n",
        "loc_emb = Permute((2, 1, 3))(loc_emb)\n",
        "cat_emb = RepeatVector(num_locations)(cat_emb)\n",
        "cat_emb = Reshape((num_locations, num_categories, num_embed_cat))(cat_emb)\n",
        "# attention\n",
        "ita = Concatenate(axis=-1)([state_h, loc_emb, cat_emb]) #shape(num_locations, num_categories, concatsize)\n",
        "ita = Dense(lstm_dim, activation='tanh', name = 'attention_dense')(ita)  # expected shape(None, num_locations, num_categories, lstm_dim)\n",
        "alpha = Reshape((num_locations * num_categories, lstm_dim))(ita)\n",
        "alpha = Softmax(axis=1)(alpha)\n",
        "alpha = Reshape((num_locations, num_categories, lstm_dim))(alpha)\n",
        "attention = Multiply()([alpha, state_h])  # expected shape(None, num_locations, num_categories, lstm_dim)\n",
        "# final output\n",
        "output = Dense(1, activation=\"sigmoid\", name = 'prediction_dense')(attention)\n",
        "output = Reshape((num_locations, num_categories))(output)\n",
        "mist = Model(inputs=[event_input, loc_emb_input, cat_emb_input], outputs=output)\n",
        "adam = keras.optimizers.Adam(lr=0.3)\n",
        "def bce_loss(y_true, y_pred):\n",
        "    y_true = K.batch_flatten(y_true)\n",
        "    y_pred = K.batch_flatten(y_pred)\n",
        "    return K.binary_crossentropy(y_true, y_pred)\n",
        "mist.compile(optimizer='adam', loss=bce_loss)\n",
        "# mist.compile(optimizer=adam, loss='binary_crossentropy')\n",
        "# # prepare data\n",
        "# features = np.load('../Chicago_data_MiST/feature2020-02-28_18:34:57.npy', allow_pickle = True)\n",
        "# labels = np.load('../Chicago_data_MiST/label2020-02-28_18:34:57.npy', allow_pickle = True)\n",
        "# features = features.reshape((features.shape[0], num_timeslots, -1))\n",
        "# locations = list(range(num_locations))\n",
        "# loc_encoding = to_categorical(locations)\n",
        "# locs = np.array([loc_encoding for i in range(features.shape[0])])\n",
        "# categories = list(range(num_categories))\n",
        "# cat_encoding = to_categorical(categories)\n",
        "# cats = np.array([cat_encoding for i in range(features.shape[0])])\n",
        "# features_train, features_test, labels_train, labels_test, locs_train, locs_test, cats_train, cats_test = train_test_split(\n",
        "#     features, labels, locs, cats, test_size = 0.2)\n",
        "# print(labels_train.shape)\n",
        "\n",
        "# CRIME-LA\n",
        "# train = np.load('DCRNN/data/CRIME-%s/%d/train.npz'%(city,month), allow_pickle = True)\n",
        "# test = np.load('DCRNN/data/CRIME-%s/%d/test.npz'%(city,month), allow_pickle=True)\n",
        "# val = np.load('DCRNN/data/CRIME-%s/%d/val.npz'%(city,month),allow_pickle=True)\n",
        "\n",
        "train = np.load('/content/data_2019_for_mist/data/' + str(d.tr) + '/train.npz', allow_pickle = True)\n",
        "test = np.load('/content/data_2019_for_mist/data/' + str(d.tr) + '/test.npz', allow_pickle=True)\n",
        "val = np.load('/content/data_2019_for_mist/data/' + str(d.tr) + '/val.npz', allow_pickle=True)\n",
        "\n",
        "features_train, features_test, labels_train, labels_test = train[\"x\"], test[\"x\"], train[\"y\"], test[\"y\"]\n",
        "features_train, features_test, labels_train, labels_test = features_train.reshape((features_train.shape[0],\n",
        "                                                                                   num_timeslots, -1)), \\\n",
        "                                                           features_test.reshape((features_test.shape[0],\n",
        "                                                                                  num_timeslots, -1)), \\\n",
        "                                                           np.squeeze(labels_train, axis=1), np.squeeze(labels_test,\n",
        "                                                                                                        axis = 1)\n",
        "val_x, val_y = val[\"x\"], val[\"y\"]\n",
        "val_x, val_y = val_x.reshape((val_x.shape[0],\n",
        "                              num_timeslots, -1)), \\\n",
        "               np.squeeze(val_y, axis = 1)\n",
        "\n",
        "\n",
        "# locations = list(range(num_locations))\n",
        "# loc_encoding = to_categorical(locations)\n",
        "loc_emb_ge = pd.read_csv('/content/embedding_file/emb_file_chi.txt',header=None)\n",
        "loc_encoding = np.array(loc_emb_ge)\n",
        "loc_encoding = loc_encoding.astype(np.float32)\n",
        "\n",
        "categories = list(range(num_categories))\n",
        "cat_encoding = to_categorical(categories)\n",
        "\n",
        "locs_train, locs_test, cats_train, cats_test = np.array([loc_encoding for i in range(features_train.shape[0])]), \\\n",
        "                                               np.array([loc_encoding for i in range(features_test.shape[0])]), \\\n",
        "                                               np.array([cat_encoding for i in range(features_train.shape[0])]), \\\n",
        "                                               np.array([cat_encoding for i in range(features_test.shape[0])])\n",
        "\n",
        "locs_val, cats_val = np.array([loc_encoding for i in range(val_x.shape[0])]), \\\n",
        "                     np.array([cat_encoding for i in range(val_x.shape[0])])\n",
        "\n",
        "#history = LossHistory()\n",
        "# train data\n",
        "history = mist.fit([features_train, locs_train, cats_train], labels_train, validation_data=[[val_x, locs_val,\n",
        "                                                                                             cats_val], val_y],\n",
        "                   batch_size=32, epochs=epoch)\n",
        "#,callbacks=[history])\n",
        "\n",
        "y_pred = mist.predict([features_test, locs_test, cats_test])\n",
        "print(np.shape(labels_test.reshape((labels_test.shape[0],-1))), np.shape(y_pred.reshape((labels_test.shape[0],-1))))\n",
        "\n",
        "\n",
        "\n",
        "#print(\"macro-f1:\", metrics.f1_score(), y_pred.reshape((labels_test.shape[0],-1)), average = 'macro')\n",
        "#test_reshape = labels_test.reshape((labels_test.shape[0],-1))\n",
        "#predict_reshape = y_pred.reshape((labels_test.shape[0],-1))\n",
        "\n",
        "test_reshape = labels_test.reshape((-1,8))\n",
        "predict_reshape = y_pred.reshape((-1,8))\n",
        "\n",
        "# ## EDITED BY ALIF\n",
        "# pickle.dump(predict_reshape, open('/content/drive/MyDrive/Thesis/MIST_TEMPORAL/preds_before_threshold_' + str(tr) +'.pkl', 'wb'))\n",
        "\n",
        "#predict_reshape = sigmoid(predict_reshape)\n",
        "pre_ratio = np.count_nonzero(labels_test) / np.size(labels_test)# the ratio of normal events in the test set\n",
        "print(\"The ratio of abnormal events in the test set is:\", pre_ratio)\n",
        "ss = MinMaxScaler(feature_range=(0, 1))\n",
        "predict_reshape = ss.fit_transform(predict_reshape)\n",
        "predict_reshape[predict_reshape >= pre_ratio] = 1\n",
        "predict_reshape[predict_reshape < pre_ratio] = 0\n",
        "\n",
        "# ## EDITED BY ALIF\n",
        "# f = open(\"/content/drive/MyDrive/Thesis/MIST_TEMPORAL/threshold_\" + str(tr) + '.txt', 'w')\n",
        "# f.write(str(pre_ratio))\n",
        "# f.close()\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(test_reshape.ravel(), predict_reshape.ravel())\n",
        "auc_keras = auc(fpr, tpr)\n",
        "\n",
        "macro_f1 = metrics.f1_score(test_reshape, predict_reshape, average = 'macro')\n",
        "micro_f1 = metrics.f1_score(test_reshape, predict_reshape, average = 'micro')\n",
        "\n",
        "# ## EDITED BY ALIF\n",
        "# MAE_score = mae(test_reshape, predict_reshape)\n",
        "# MSE_score =  mse(test_reshape, predict_reshape)\n",
        "\n",
        "print(\"auc for MIST: \", auc_keras)\n",
        "print(\"macro-f1:\", macro_f1)\n",
        "print(\"micro-f1:\", micro_f1)\n",
        "\n",
        "# ## EDITED BY ALIF\n",
        "# print(\"mae:\", MAE_score)\n",
        "# print(\"mse\",MSE_score)\n",
        "# print('Final shape of predict_reshape:', predict_reshape.shape)\n",
        "\n",
        "## EDITED BY ALIF\n",
        "f = open(\"/content/drive/MyDrive/Thesis/MIST_TEMPORAL/Metrics/1d/\" + str(tr) + '.txt', 'w')\n",
        "# f.write(str(MAE_score))\n",
        "# f.write(\" \")\n",
        "# f.write(str(MSE_score))\n",
        "# f.write(\" \")\n",
        "f.write(str(macro_f1))\n",
        "f.write(\" \")\n",
        "f.write(str(micro_f1))\n",
        "f.close()\n",
        "\n",
        "## EDITED BY ALIF\n",
        "pickle.dump(test_reshape, open('/content/drive/MyDrive/Thesis/MIST_TEMPORAL/true_preds/1d/trues_' + str(tr) +'.pkl', 'wb'))\n",
        "pickle.dump(predict_reshape, open('/content/drive/MyDrive/Thesis/MIST_TEMPORAL/true_preds/1d/preds_after_threshold_' + str(tr) +'.pkl', 'wb'))\n",
        "\n",
        "# # list all data in history\n",
        "# print(history.history.keys())\n",
        "\n",
        "# # summarize history for loss\n",
        "\n",
        "# plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "# plt.title('model loss')\n",
        "# plt.ylabel('loss')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
        "# plt.savefig('mist_los.png')\n",
        "# print(\"successfully saved the fig\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9ljYCeS435Y"
      },
      "outputs": [],
      "source": [
        "# for REGRESSION\n",
        "\n",
        "import os\n",
        "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
        "\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import time\n",
        "import sklearn\n",
        "from sklearn.utils.extmath import softmax\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, RepeatVector, Permute, Concatenate, Reshape, Softmax, Multiply, TimeDistributed, Flatten\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "import keras.backend as K\n",
        "import argparse\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc, roc_auc_score\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "import matplotlib.pyplot as plt\n",
        "# from keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "import sys\n",
        "import argparse as Ap\n",
        "argp = Ap.ArgumentParser()\n",
        "argp.add_argument(\"--tr\", default=25, type=int, help=\"Target region\")\n",
        "argp.add_argument(\"--epoch\", default=150, type=int, help=\"Epoch\")\n",
        "d = argp.parse_args(sys.argv[1:])\n",
        "\n",
        "tr = d.tr\n",
        "epoch = d.epoch\n",
        "\n",
        "# def emb(dim_input, dim_emb):\n",
        "def sigmoid(array):\n",
        "    for i in range(len(array)):\n",
        "        for j in range(len(array[i])):\n",
        "            # print(\"a :\", array[i][j])\n",
        "            array[i][j] = 1/(1 + np.exp(-array[i][j]))\n",
        "            # print(\"b :\", array[i][j])\n",
        "    return array\n",
        "\n",
        "# num_locations = 113\n",
        "num_locations = 77\n",
        "#77 for Chi and 113 for LA\n",
        "\n",
        "num_categories = 8\n",
        "num_timeslots = 8\n",
        "\n",
        "num_embed_loc = 4\n",
        "# num_embed_cat = 16\n",
        "\n",
        "# for chi\n",
        "num_embed_cat = 8\n",
        "\n",
        "lstm_dim = 32\n",
        "\n",
        "# build lstm\n",
        "event_input = Input(shape=(num_timeslots, num_locations * num_categories), name=\"event_input\")\n",
        "local_layer = Permute((2,1))(event_input)\n",
        "local_layer = Reshape((num_locations * num_categories, num_timeslots, 1))(local_layer)\n",
        "lstm = TimeDistributed(LSTM(lstm_dim))\n",
        "encoder_outputs = lstm(local_layer) # expected shape(num_locations * num_categories, lstm_dim)\n",
        "# lstm = LSTM(lstm_dim, return_state=True)\n",
        "# encoder_outputs, state_h, state_c = lstm(event_input)\n",
        "state_h = Reshape((num_locations, num_categories, lstm_dim))(encoder_outputs)\n",
        "\n",
        "# prepare embeddings, here we assume embeddings are learnable\n",
        "#loc_emb_input = Input(shape=(num_locations, num_locations), name=\"loc_emb_input\")\n",
        "# loc_emb_input = Input(shape=(num_locations, 16), name=\"loc_emb_input\")\n",
        "loc_emb_input = Input(shape=(num_locations, 8), name=\"loc_emb_input\")\n",
        "\n",
        "cat_emb_input = Input(shape=(num_categories, num_categories), name=\"cat_emb_input\")\n",
        "loc_emb = Dense(num_embed_loc, name = 'loc_emb_dense')(loc_emb_input)\n",
        "cat_emb = Dense(num_embed_cat, name = 'cat_emb_dense')(cat_emb_input)\n",
        "loc_emb = Flatten()(loc_emb)\n",
        "cat_emb = Flatten()(cat_emb)\n",
        "# loc_emb_input = Input(shape = (num_locations, num_embed_loc), name = \"loc_emb_input\")\n",
        "# cat_emb_input = Input(shape = (num_categories, num_embed_cat), name = \"cat_emb_input\")\n",
        "loc_emb = RepeatVector(num_categories)(loc_emb)\n",
        "loc_emb = Reshape((num_categories, num_locations, num_embed_loc))(loc_emb) # shape(num_categories, num_locations, num_embed_loc)\n",
        "loc_emb = Permute((2, 1, 3))(loc_emb)\n",
        "cat_emb = RepeatVector(num_locations)(cat_emb)\n",
        "cat_emb = Reshape((num_locations, num_categories, num_embed_cat))(cat_emb)\n",
        "# attention\n",
        "ita = Concatenate(axis=-1)([state_h, loc_emb, cat_emb]) #shape(num_locations, num_categories, concatsize)\n",
        "ita = Dense(lstm_dim, activation='tanh', name = 'attention_dense')(ita)  # expected shape(None, num_locations, num_categories, lstm_dim)\n",
        "alpha = Reshape((num_locations * num_categories, lstm_dim))(ita)\n",
        "alpha = Softmax(axis=1)(alpha)\n",
        "alpha = Reshape((num_locations, num_categories, lstm_dim))(alpha)\n",
        "attention = Multiply()([alpha, state_h])  # expected shape(None, num_locations, num_categories, lstm_dim)\n",
        "# final output\n",
        "output = Dense(1, activation=\"sigmoid\", name = 'prediction_dense')(attention)\n",
        "output = Reshape((num_locations, num_categories))(output)\n",
        "mist = Model(inputs=[event_input, loc_emb_input, cat_emb_input], outputs=output)\n",
        "adam = keras.optimizers.Adam(lr=0.3)\n",
        "\n",
        "# def bce_loss(y_true, y_pred):\n",
        "#     y_true = K.batch_flatten(y_true)\n",
        "#     y_pred = K.batch_flatten(y_pred)\n",
        "#     return K.binary_crossentropy(y_true, y_pred)\n",
        "\n",
        "def mse_loss(y_true, y_pred):\n",
        "    y_true = K.batch_flatten(y_true)\n",
        "    y_pred = K.batch_flatten(y_pred)\n",
        "    return K.mean(K.square(y_true - y_pred))\n",
        "\n",
        "mist.compile(optimizer='adam', loss=mse_loss)\n",
        "# mist.compile(optimizer=adam, loss='binary_crossentropy')\n",
        "# # prepare data\n",
        "# features = np.load('../Chicago_data_MiST/feature2020-02-28_18:34:57.npy', allow_pickle = True)\n",
        "# labels = np.load('../Chicago_data_MiST/label2020-02-28_18:34:57.npy', allow_pickle = True)\n",
        "# features = features.reshape((features.shape[0], num_timeslots, -1))\n",
        "# locations = list(range(num_locations))\n",
        "# loc_encoding = to_categorical(locations)\n",
        "# locs = np.array([loc_encoding for i in range(features.shape[0])])\n",
        "# categories = list(range(num_categories))\n",
        "# cat_encoding = to_categorical(categories)\n",
        "# cats = np.array([cat_encoding for i in range(features.shape[0])])\n",
        "# features_train, features_test, labels_train, labels_test, locs_train, locs_test, cats_train, cats_test = train_test_split(\n",
        "#     features, labels, locs, cats, test_size = 0.2)\n",
        "# print(labels_train.shape)\n",
        "\n",
        "# CRIME-LA\n",
        "# train = np.load('DCRNN/data/CRIME-%s/%d/train.npz'%(city,month), allow_pickle = True)\n",
        "# test = np.load('DCRNN/data/CRIME-%s/%d/test.npz'%(city,month), allow_pickle=True)\n",
        "# val = np.load('DCRNN/data/CRIME-%s/%d/val.npz'%(city,month),allow_pickle=True)\n",
        "\n",
        "train = np.load('/content/data_2019_for_mist/data/' + str(d.tr) + '/train.npz', allow_pickle = True)\n",
        "test = np.load('/content/data_2019_for_mist/data/' + str(d.tr) + '/test.npz', allow_pickle=True)\n",
        "val = np.load('/content/data_2019_for_mist/data/' + str(d.tr) + '/val.npz', allow_pickle=True)\n",
        "\n",
        "features_train, features_test, labels_train, labels_test = train[\"x\"], test[\"x\"], train[\"y\"], test[\"y\"]\n",
        "features_train, features_test, labels_train, labels_test = features_train.reshape((features_train.shape[0],\n",
        "                                                                                   num_timeslots, -1)), \\\n",
        "                                                           features_test.reshape((features_test.shape[0],\n",
        "                                                                                  num_timeslots, -1)), \\\n",
        "                                                           np.squeeze(labels_train, axis=1), np.squeeze(labels_test,\n",
        "                                                                                                        axis = 1)\n",
        "val_x, val_y = val[\"x\"], val[\"y\"]\n",
        "val_x, val_y = val_x.reshape((val_x.shape[0],\n",
        "                              num_timeslots, -1)), \\\n",
        "               np.squeeze(val_y, axis = 1)\n",
        "\n",
        "\n",
        "# locations = list(range(num_locations))\n",
        "# loc_encoding = to_categorical(locations)\n",
        "loc_emb_ge = pd.read_csv('/content/embedding_file/emb_file_chi.txt',header=None)\n",
        "loc_encoding = np.array(loc_emb_ge)\n",
        "loc_encoding = loc_encoding.astype(np.float32)\n",
        "\n",
        "categories = list(range(num_categories))\n",
        "cat_encoding = to_categorical(categories)\n",
        "\n",
        "locs_train, locs_test, cats_train, cats_test = np.array([loc_encoding for i in range(features_train.shape[0])]), \\\n",
        "                                               np.array([loc_encoding for i in range(features_test.shape[0])]), \\\n",
        "                                               np.array([cat_encoding for i in range(features_train.shape[0])]), \\\n",
        "                                               np.array([cat_encoding for i in range(features_test.shape[0])])\n",
        "\n",
        "locs_val, cats_val = np.array([loc_encoding for i in range(val_x.shape[0])]), \\\n",
        "                     np.array([cat_encoding for i in range(val_x.shape[0])])\n",
        "\n",
        "#history = LossHistory()\n",
        "# train data\n",
        "history = mist.fit([features_train, locs_train, cats_train], labels_train, validation_data=[[val_x, locs_val,\n",
        "                                                                                             cats_val], val_y],\n",
        "                   batch_size=32, epochs=epoch)\n",
        "#,callbacks=[history])\n",
        "\n",
        "y_pred = mist.predict([features_test, locs_test, cats_test])\n",
        "print(np.shape(labels_test.reshape((labels_test.shape[0],-1))), np.shape(y_pred.reshape((labels_test.shape[0],-1))))\n",
        "\n",
        "\n",
        "\n",
        "#print(\"macro-f1:\", metrics.f1_score(), y_pred.reshape((labels_test.shape[0],-1)), average = 'macro')\n",
        "#test_reshape = labels_test.reshape((labels_test.shape[0],-1))\n",
        "#predict_reshape = y_pred.reshape((labels_test.shape[0],-1))\n",
        "\n",
        "test_reshape = labels_test.reshape((-1,8))\n",
        "predict_reshape = y_pred.reshape((-1,8))\n",
        "\n",
        "# ## EDITED BY ALIF\n",
        "# pickle.dump(predict_reshape, open('/content/drive/MyDrive/Thesis/MIST_TEMPORAL/preds_before_threshold_' + str(tr) +'.pkl', 'wb'))\n",
        "\n",
        "#predict_reshape = sigmoid(predict_reshape)\n",
        "pre_ratio = np.count_nonzero(labels_test) / np.size(labels_test)# the ratio of normal events in the test set\n",
        "print(\"The ratio of abnormal events in the test set is:\", pre_ratio)\n",
        "ss = MinMaxScaler(feature_range=(0, 1))\n",
        "predict_reshape = ss.fit_transform(predict_reshape)\n",
        "predict_reshape[predict_reshape >= pre_ratio] = 1\n",
        "predict_reshape[predict_reshape < pre_ratio] = 0\n",
        "\n",
        "# ## EDITED BY ALIF\n",
        "# f = open(\"/content/drive/MyDrive/Thesis/MIST_TEMPORAL/threshold_\" + str(tr) + '.txt', 'w')\n",
        "# f.write(str(pre_ratio))\n",
        "# f.close()\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(test_reshape.ravel(), predict_reshape.ravel())\n",
        "auc_keras = auc(fpr, tpr)\n",
        "\n",
        "# macro_f1 = metrics.f1_score(test_reshape, predict_reshape, average = 'macro')\n",
        "# micro_f1 = metrics.f1_score(test_reshape, predict_reshape, average = 'micro')\n",
        "\n",
        "## EDITED BY ALIF\n",
        "MAE_score = mae(test_reshape, predict_reshape)\n",
        "MSE_score =  mse(test_reshape, predict_reshape)\n",
        "\n",
        "# print(\"auc for MIST: \", auc_keras)\n",
        "# print(\"macro-f1:\", macro_f1)\n",
        "# print(\"micro-f1:\", micro_f1)\n",
        "\n",
        "## EDITED BY ALIF\n",
        "print(\"mae:\", MAE_score)\n",
        "print(\"mse\",MSE_score)\n",
        "# print('Final shape of predict_reshape:', predict_reshape.shape)\n",
        "\n",
        "## EDITED BY ALIF\n",
        "f = open(\"/content/drive/MyDrive/Thesis/MIST_TEMPORAL/Metrics/r_1d/\" + str(tr) + '.txt', 'w')\n",
        "f.write(str(MAE_score))\n",
        "f.write(\" \")\n",
        "f.write(str(MSE_score))\n",
        "f.write(\" \")\n",
        "# f.write(str(macro_f1))\n",
        "# f.write(\" \")\n",
        "# f.write(str(micro_f1))\n",
        "# f.close()\n",
        "\n",
        "## EDITED BY ALIF\n",
        "pickle.dump(test_reshape, open('/content/drive/MyDrive/Thesis/MIST_TEMPORAL/true_preds/r_1d/trues_' + str(tr) +'.pkl', 'wb'))\n",
        "pickle.dump(predict_reshape, open('/content/drive/MyDrive/Thesis/MIST_TEMPORAL/true_preds/r_1d/preds_after_threshold_' + str(tr) +'.pkl', 'wb'))\n",
        "\n",
        "# # list all data in history\n",
        "# print(history.history.keys())\n",
        "\n",
        "# # summarize history for loss\n",
        "\n",
        "# plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "# plt.title('model loss')\n",
        "# plt.ylabel('loss')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
        "# plt.savefig('mist_los.png')\n",
        "# print(\"successfully saved the fig\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}